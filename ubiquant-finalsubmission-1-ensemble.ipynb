{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d8ce27",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-12T08:39:23.073050Z",
     "iopub.status.busy": "2022-04-12T08:39:23.066408Z",
     "iopub.status.idle": "2022-04-12T08:39:23.089574Z",
     "shell.execute_reply": "2022-04-12T08:39:23.089079Z",
     "shell.execute_reply.started": "2022-04-12T08:33:20.376651Z"
    },
    "papermill": {
     "duration": 0.047149,
     "end_time": "2022-04-12T08:39:23.089697",
     "exception": false,
     "start_time": "2022-04-12T08:39:23.042548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/ubiquantfinalsubmission1/two128-bestenco-test-1_0.h5\n",
      "../input/ubiquantfinalsubmission1/two256drop0.2-bestenco-test-1_0.h5\n",
      "../input/ubiquantfinalsubmission1/del-355-420-best-enco-kfold-test_1.h5\n",
      "../input/ubiquantfinalsubmission1/512_256512-bestenco-kfold_1.h5\n",
      "../input/ubiquantfinalsubmission1/encoder-best1-512_128-seed34_m1.h5\n",
      "../input/ubiquantfinalsubmission1/512_256512-bestenco-kfold_0.h5\n",
      "../input/ubiquantfinalsubmission1/512_128-512best1-enco_1.h5\n",
      "../input/ubiquantfinalsubmission1/512_128-512best1-enco_0.h5\n",
      "../input/ubiquantfinalsubmission1/encoder-best1-512_128-seed34_m2.h5\n",
      "../input/ubiquantfinalsubmission1/two256drop0.2-bestenco-test-1_2.h5\n",
      "../input/ubiquantfinalsubmission1/del-355-420-best-enco-kfold-test_0.h5\n",
      "../input/ubiquantfinalsubmission1/encoder-best1-384-m2.h5\n",
      "../input/ubiquantfinalsubmission1/two256drop0.2-bestenco-test-1_1.h5\n",
      "../input/ubiquantfinalsubmission1/encoder-best1-512_128-0.153-model_1.h5\n",
      "../input/ubiquantfinalsubmission1/encoder-best1-512_128-0.153-model_0.h5\n",
      "../input/ubiquantfinalsubmission1/512_256512-bestenco-kfold_2.h5\n",
      "../input/ubiquantfinalsubmission1/del-355-420-best-enco-kfold-test_2.h5\n",
      "../input/ubiquantfinalsubmission1/two128-bestenco-test-1_2.h5\n",
      "../input/ubiquantfinalsubmission1/two128-bestenco-test-1_1.h5\n",
      "../input/ubiquantfinalsubmission1/256dropmove-bestenco-test-1_1.h5\n",
      "../input/ubiquantfinalsubmission1/encoder-best1-512_128-0.153-model_2.h5\n",
      "../input/ubiquantfinalsubmission1/encoder-best1-384-m1.h5\n",
      "../input/ubiquantfinalsubmission1/encoder-best1-384-m0.h5\n",
      "../input/ubiquantfinalsubmission1/256dropmove-bestenco-test-1_0.h5\n",
      "../input/ubiquantfinalsubmission1/512_128-512best1-enco_2.h5\n",
      "../input/ubiquantfinalsubmission1/encoder-best1-512_128-seed34_m0.h5\n",
      "../input/ubiquantfinalsubmission1/256dropmove-bestenco-test-1_2.h5\n",
      "../input/ubiquantfinalsubmission1/full_train-cur_best_enco-ep7-loss0.8151.h5/full_train-cur_best_enco-ep7-loss0.8151.h5\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input/ubiquantfinalsubmission1'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2a331c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:39:23.136449Z",
     "iopub.status.busy": "2022-04-12T08:39:23.135913Z",
     "iopub.status.idle": "2022-04-12T08:39:28.715427Z",
     "shell.execute_reply": "2022-04-12T08:39:28.714923Z",
     "shell.execute_reply.started": "2022-04-12T08:33:20.51013Z"
    },
    "papermill": {
     "duration": 5.604245,
     "end_time": "2022-04-12T08:39:28.715557",
     "exception": false,
     "start_time": "2022-04-12T08:39:23.111312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb382b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:39:28.757349Z",
     "iopub.status.busy": "2022-04-12T08:39:28.756523Z",
     "iopub.status.idle": "2022-04-12T08:40:28.565018Z",
     "shell.execute_reply": "2022-04-12T08:40:28.565459Z",
     "shell.execute_reply.started": "2022-04-12T08:33:26.149954Z"
    },
    "papermill": {
     "duration": 59.831091,
     "end_time": "2022-04-12T08:40:28.565623",
     "exception": false,
     "start_time": "2022-04-12T08:39:28.734532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')\n",
    "data = data.drop(columns=['time_id', 'row_id', 'investment_id', 'target']).values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b72ef3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:28.608942Z",
     "iopub.status.busy": "2022-04-12T08:40:28.608277Z",
     "iopub.status.idle": "2022-04-12T08:40:28.610497Z",
     "shell.execute_reply": "2022-04-12T08:40:28.610934Z",
     "shell.execute_reply.started": "2022-04-12T08:34:27.001608Z"
    },
    "papermill": {
     "duration": 0.026105,
     "end_time": "2022-04-12T08:40:28.611063",
     "exception": false,
     "start_time": "2022-04-12T08:40:28.584958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mish(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Mish, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        return inputs * K.tanh(K.softplus(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5d23754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:28.658619Z",
     "iopub.status.busy": "2022-04-12T08:40:28.658105Z",
     "iopub.status.idle": "2022-04-12T08:40:31.311920Z",
     "shell.execute_reply": "2022-04-12T08:40:31.312487Z",
     "shell.execute_reply.started": "2022-04-12T08:34:27.010085Z"
    },
    "papermill": {
     "duration": 2.682903,
     "end_time": "2022-04-12T08:40:31.312644",
     "exception": false,
     "start_time": "2022-04-12T08:40:28.629741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 08:40:28.780903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 08:40:28.896579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 08:40:28.897396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 08:40:28.898945: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-12 08:40:28.899374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 08:40:28.900300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 08:40:28.901173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 08:40:30.906101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 08:40:30.907031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 08:40:30.907749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-12 08:40:30.908935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "input_dim = 300\n",
    "\n",
    "def build_encoder_1(input_dim, noise_rate=0.05):\n",
    "    ori_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    encode = layers.BatchNormalization()(ori_input)\n",
    "    encode = layers.GaussianNoise(stddev=noise_rate)(encode)\n",
    "    encode = layers.Dense(256, activation=activations.swish)(encode)\n",
    "    decode = layers.Dropout(0.2)(encode)\n",
    "    decode = layers.Dense(input_dim, name='decoded')(decode)\n",
    "    x = layers.Dense(160)(decode)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(1, name='target_out')(x)\n",
    "\n",
    "    encoder = models.Model(inputs=[ori_input], outputs=[encode])\n",
    "    autoencoder = models.Model(inputs=[ori_input], outputs=[decode, x])\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "autoencoder, encoder_1 = build_encoder_1(input_dim)\n",
    "encoder_1.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1628b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.365971Z",
     "iopub.status.busy": "2022-04-12T08:40:31.365428Z",
     "iopub.status.idle": "2022-04-12T08:40:31.454199Z",
     "shell.execute_reply": "2022-04-12T08:40:31.453772Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.458734Z"
    },
    "papermill": {
     "duration": 0.120865,
     "end_time": "2022-04-12T08:40:31.454315",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.333450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_encoder(input_dim, noise_rate=0.05):\n",
    "    ori_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    encode = layers.BatchNormalization()(ori_input)\n",
    "    encode = layers.GaussianNoise(stddev=noise_rate)(encode)\n",
    "    encode = layers.Dense(256)(encode)\n",
    "    encode = Mish()(encode)\n",
    "    decode = layers.Dropout(0.2)(encode)\n",
    "    decode = layers.Dense(input_dim, name='decoded')(decode)\n",
    "    x = layers.Dense(265, use_bias=False)(decode)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(1, name='target_out')(x)\n",
    "\n",
    "    encoder = models.Model(inputs=[ori_input], outputs=[encode])\n",
    "    autoencoder = models.Model(inputs=[ori_input], outputs=[decode, x])\n",
    "    return autoencoder, encoder\n",
    "\n",
    "autoencoder, encoder_0 = build_encoder(input_dim)\n",
    "encoder_0.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44f5d510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.503335Z",
     "iopub.status.busy": "2022-04-12T08:40:31.501818Z",
     "iopub.status.idle": "2022-04-12T08:40:31.503958Z",
     "shell.execute_reply": "2022-04-12T08:40:31.504353Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.561983Z"
    },
    "papermill": {
     "duration": 0.030715,
     "end_time": "2022-04-12T08:40:31.504481",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.473766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_512_128(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation=activations.swish)(x)\n",
    "    \n",
    "    x = layers.Concatenate()([x,  ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad169d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.552878Z",
     "iopub.status.busy": "2022-04-12T08:40:31.552178Z",
     "iopub.status.idle": "2022-04-12T08:40:31.556068Z",
     "shell.execute_reply": "2022-04-12T08:40:31.555348Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.575201Z"
    },
    "papermill": {
     "duration": 0.032437,
     "end_time": "2022-04-12T08:40:31.556172",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.523735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_512_128_mish(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a6c305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.605064Z",
     "iopub.status.busy": "2022-04-12T08:40:31.604391Z",
     "iopub.status.idle": "2022-04-12T08:40:31.606630Z",
     "shell.execute_reply": "2022-04-12T08:40:31.607117Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.589181Z"
    },
    "papermill": {
     "duration": 0.031854,
     "end_time": "2022-04-12T08:40:31.607244",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.575390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_384(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(384, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation=activations.swish)(x)\n",
    "    \n",
    "    x = layers.Concatenate()([x,  ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e296fba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.655997Z",
     "iopub.status.busy": "2022-04-12T08:40:31.655308Z",
     "iopub.status.idle": "2022-04-12T08:40:31.657747Z",
     "shell.execute_reply": "2022-04-12T08:40:31.657340Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.601865Z"
    },
    "papermill": {
     "duration": 0.031268,
     "end_time": "2022-04-12T08:40:31.657851",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.626583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_512_256_512(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "    #     ox_enco = layers.BatchNormalization()(ox_enco)\n",
    "    #     ox_enco = layers.Dense(256, activation=activations.swish)(ox_enco)\n",
    "\n",
    "    #     inv_input = Input(shape=(1,), dtype='int64')\n",
    "    #     inv_emb = layers.Embedding(inv_vocb, 16)\n",
    "    #     squeeze_layer = Squeeze()\n",
    "    #     inv_enco = inv_emb(inv_input)\n",
    "    #     inv_enco = squeeze_layer(inv_enco)\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation=activations.swish)(x)\n",
    "\n",
    "    #     x = layers.BatchNormalization()(x)\n",
    "    #     x = layers.Activation(activations.swish)(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    #     x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    #     x = layers.Dense(128, use_bias=False)(x)\n",
    "    #     x = layers.BatchNormalization()(x)\n",
    "    #     x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    #     x = layers.Dropout(0.1)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84351b0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.706675Z",
     "iopub.status.busy": "2022-04-12T08:40:31.706161Z",
     "iopub.status.idle": "2022-04-12T08:40:31.709670Z",
     "shell.execute_reply": "2022-04-12T08:40:31.709253Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.618116Z"
    },
    "papermill": {
     "duration": 0.032592,
     "end_time": "2022-04-12T08:40:31.709798",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.677206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_512_128_512(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "    #     ox_enco = layers.BatchNormalization()(ox_enco)\n",
    "    #     ox_enco = layers.Dense(256, activation=activations.swish)(ox_enco)\n",
    "\n",
    "    #     inv_input = Input(shape=(1,), dtype='int64')\n",
    "    #     inv_emb = layers.Embedding(inv_vocb, 16)\n",
    "    #     squeeze_layer = Squeeze()\n",
    "    #     inv_enco = inv_emb(inv_input)\n",
    "    #     inv_enco = squeeze_layer(inv_enco)\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation=activations.swish)(x)\n",
    "    #     x = layers.BatchNormalization()(x)\n",
    "    #     x = layers.Activation(activations.swish)(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    #     x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    #     x = layers.Dense(128, use_bias=False)(x)\n",
    "    #     x = layers.BatchNormalization()(x)\n",
    "    #     x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activations.swish)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    #     x = layers.Dropout(0.1)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c6414ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.758035Z",
     "iopub.status.busy": "2022-04-12T08:40:31.757246Z",
     "iopub.status.idle": "2022-04-12T08:40:31.759016Z",
     "shell.execute_reply": "2022-04-12T08:40:31.759407Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.633097Z"
    },
    "papermill": {
     "duration": 0.030536,
     "end_time": "2022-04-12T08:40:31.759518",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.728982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_two256drop02(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c8232bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.807505Z",
     "iopub.status.busy": "2022-04-12T08:40:31.805486Z",
     "iopub.status.idle": "2022-04-12T08:40:31.809651Z",
     "shell.execute_reply": "2022-04-12T08:40:31.809233Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.646416Z"
    },
    "papermill": {
     "duration": 0.031071,
     "end_time": "2022-04-12T08:40:31.809774",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.778703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_dropmove(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ab81d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.859507Z",
     "iopub.status.busy": "2022-04-12T08:40:31.857989Z",
     "iopub.status.idle": "2022-04-12T08:40:31.860130Z",
     "shell.execute_reply": "2022-04-12T08:40:31.860530Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.660405Z"
    },
    "papermill": {
     "duration": 0.031669,
     "end_time": "2022-04-12T08:40:31.860642",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.828973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_two128(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b30d9c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.911536Z",
     "iopub.status.busy": "2022-04-12T08:40:31.910792Z",
     "iopub.status.idle": "2022-04-12T08:40:31.913172Z",
     "shell.execute_reply": "2022-04-12T08:40:31.912749Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.676139Z"
    },
    "papermill": {
     "duration": 0.033499,
     "end_time": "2022-04-12T08:40:31.913270",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.879771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_conv1d_model():\n",
    "    features_inputs = tf.keras.Input((input_dim, ), dtype=tf.float32)\n",
    "    \n",
    "    ## feature ##\n",
    "    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n",
    "    feature_x = layers.Dropout(0.1)(feature_x)\n",
    "    ## convolution 1 ##\n",
    "    feature_x = layers.Reshape((-1,1))(feature_x)\n",
    "    feature_x = layers.Conv1D(filters=16, kernel_size=4, strides=1, padding='same')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU()(feature_x)\n",
    "    ## convolution 2 ##\n",
    "    feature_x = layers.Conv1D(filters=16, kernel_size=4, strides=4, padding='same')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU()(feature_x)\n",
    "    ## convolution 3 ##\n",
    "    feature_x = layers.Conv1D(filters=64, kernel_size=4, strides=1, padding='same')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU()(feature_x)\n",
    "    ## convolution 4 ##\n",
    "    feature_x = layers.Conv1D(filters=64, kernel_size=4, strides=4, padding='same')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU()(feature_x)\n",
    "    ## convolution 5 ##\n",
    "    feature_x = layers.Conv1D(filters=64, kernel_size=4, strides=2, padding='same')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = layers.LeakyReLU()(feature_x)\n",
    "    ## flatten ##\n",
    "    feature_x = layers.Flatten()(feature_x)\n",
    "    \n",
    "    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(feature_x)\n",
    "    \n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "#     rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    model = tf.keras.Model(inputs=[features_inputs], outputs=[output])\n",
    "#     model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse, correlation])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92bf12e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:31.963418Z",
     "iopub.status.busy": "2022-04-12T08:40:31.959470Z",
     "iopub.status.idle": "2022-04-12T08:40:31.965801Z",
     "shell.execute_reply": "2022-04-12T08:40:31.965375Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.691363Z"
    },
    "papermill": {
     "duration": 0.033525,
     "end_time": "2022-04-12T08:40:31.965907",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.932382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_conv1d_model_0():\n",
    "    features_inputs = tf.keras.Input((input_dim, ), dtype=tf.float32)\n",
    "    \n",
    "    ## feature ##\n",
    "    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n",
    "    feature_x = layers.Dropout(0.1)(feature_x)\n",
    "    ## convolution 1 ##\n",
    "    feature_x = layers.Reshape((-1,1))(feature_x)\n",
    "    feature_x = layers.Conv1D(filters=16, kernel_size=4, strides=1, padding='same')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = Mish()(feature_x)\n",
    "    ## convolution 2 ##\n",
    "    feature_x = layers.Conv1D(filters=16, kernel_size=4, strides=4, padding='same')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = Mish()(feature_x)\n",
    "    ## convolution 3 ##\n",
    "    feature_x = layers.Conv1D(filters=64, kernel_size=4, strides=1, padding='same')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x =Mish()(feature_x)\n",
    "    ## convolution 4 ##\n",
    "    feature_x = layers.Conv1D(filters=64, kernel_size=4, strides=4, padding='same')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = Mish()(feature_x)\n",
    "    ## convolution 5 ##\n",
    "    feature_x = layers.Conv1D(filters=64, kernel_size=4, strides=2, padding='same')(feature_x)\n",
    "    feature_x = layers.BatchNormalization()(feature_x)\n",
    "    feature_x = Mish()(feature_x)\n",
    "    ## flatten ##\n",
    "    feature_x = layers.Flatten()(feature_x)\n",
    "    \n",
    "    x = layers.Dense(512, kernel_regularizer=\"l2\")(feature_x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(128, kernel_regularizer=\"l2\")(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(32, kernel_regularizer=\"l2\")(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "#     rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    model = tf.keras.Model(inputs=[features_inputs], outputs=[output])\n",
    "#     model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse, correlation])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecfc16e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:32.021786Z",
     "iopub.status.busy": "2022-04-12T08:40:32.020848Z",
     "iopub.status.idle": "2022-04-12T08:40:41.506800Z",
     "shell.execute_reply": "2022-04-12T08:40:41.507979Z",
     "shell.execute_reply.started": "2022-04-12T08:34:29.707691Z"
    },
    "papermill": {
     "duration": 9.523099,
     "end_time": "2022-04-12T08:40:41.508186",
     "exception": false,
     "start_time": "2022-04-12T08:40:31.985087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# 0.1537\n",
    "model_512_128_m0 = build_model_512_128(encoder_1)\n",
    "model_512_128_m0.load_weights('../input/ubiquantfinalsubmission1/encoder-best1-512_128-0.153-model_0.h5')\n",
    "model_512_128_m1 = build_model_512_128(encoder_1)\n",
    "model_512_128_m1.load_weights('../input/ubiquantfinalsubmission1/encoder-best1-512_128-0.153-model_1.h5')\n",
    "\n",
    "# 0.1536\n",
    "model_384_m1 = build_model_384(encoder_1)\n",
    "model_384_m1.load_weights('../input/ubiquantfinalsubmission1/encoder-best1-384-m1.h5')\n",
    "model_384_m2 = build_model_384(encoder_1)\n",
    "model_384_m2.load_weights('../input/ubiquantfinalsubmission1/encoder-best1-384-m2.h5')\n",
    "\n",
    "\n",
    "# 0.1537\n",
    "model_512_256_512_m0 = build_model_512_256_512(encoder_1)\n",
    "model_512_256_512_m0.load_weights('../input/ubiquantfinalsubmission1/512_256512-bestenco-kfold_0.h5')\n",
    "model_512_256_512_m1 = build_model_512_256_512(encoder_1)\n",
    "model_512_256_512_m1.load_weights('../input/ubiquantfinalsubmission1/512_256512-bestenco-kfold_1.h5')\n",
    "model_512_256_512_m2 = build_model_512_256_512(encoder_1)\n",
    "model_512_256_512_m2.load_weights('../input/ubiquantfinalsubmission1/512_256512-bestenco-kfold_2.h5')\n",
    "\n",
    "# 0.1533\n",
    "model_512_128_512_m0 = build_model_512_128_512(encoder_1)\n",
    "model_512_128_512_m0.load_weights('../input/ubiquantfinalsubmission1/512_128-512best1-enco_0.h5')\n",
    "model_512_128_512_m1 = build_model_512_128_512(encoder_1)\n",
    "model_512_128_512_m1.load_weights('../input/ubiquantfinalsubmission1/512_128-512best1-enco_1.h5')\n",
    "model_512_128_512_m2 = build_model_512_128_512(encoder_1)\n",
    "model_512_128_512_m2.load_weights('../input/ubiquantfinalsubmission1/512_128-512best1-enco_2.h5')\n",
    "\n",
    "\n",
    "# 0.1538, mish-best-enco\n",
    "model_two256drop_m0 = build_model_two256drop02(encoder_1)\n",
    "model_two256drop_m0.load_weights('../input/ubiquantfinalsubmission1/two256drop0.2-bestenco-test-1_0.h5')\n",
    "model_two256drop_m1 = build_model_two256drop02(encoder_1)\n",
    "model_two256drop_m1.load_weights('../input/ubiquantfinalsubmission1/two256drop0.2-bestenco-test-1_1.h5')\n",
    "model_two256drop_m2 = build_model_two256drop02(encoder_1)\n",
    "model_two256drop_m2.load_weights('../input/ubiquantfinalsubmission1/two256drop0.2-bestenco-test-1_2.h5')\n",
    "\n",
    "# 0.1534, two1280mish\n",
    "model_two128_m0 = build_model_two128(encoder_0)\n",
    "model_two128_m0.load_weights('../input/ubiquantfinalsubmission1/two128-bestenco-test-1_0.h5')\n",
    "model_two128_m1 = build_model_two128(encoder_0)\n",
    "model_two128_m1.load_weights('../input/ubiquantfinalsubmission1/two128-bestenco-test-1_1.h5')\n",
    "model_two128_m2 = build_model_two128(encoder_0)\n",
    "model_two128_m2.load_weights('../input/ubiquantfinalsubmission1/two128-bestenco-test-1_2.h5')\n",
    "\n",
    "# 0.1543\n",
    "model_dropmove_m0 = build_model_dropmove(encoder_1)\n",
    "model_dropmove_m0.load_weights('../input/ubiquantfinalsubmission1/256dropmove-bestenco-test-1_0.h5')\n",
    "model_dropmove_m1 = build_model_dropmove(encoder_1)\n",
    "model_dropmove_m1.load_weights('../input/ubiquantfinalsubmission1/256dropmove-bestenco-test-1_1.h5')\n",
    "model_dropmove_m2 = build_model_dropmove(encoder_1)\n",
    "model_dropmove_m2.load_weights('../input/ubiquantfinalsubmission1/256dropmove-bestenco-test-1_2.h5')\n",
    "\n",
    "# 0.152\n",
    "model_512_128_seed34_m0 = build_model_512_128(encoder_1)\n",
    "model_512_128_seed34_m0.load_weights('../input/ubiquantfinalsubmission1/encoder-best1-512_128-seed34_m0.h5')\n",
    "model_512_128_seed34_m1 = build_model_512_128(encoder_1)\n",
    "model_512_128_seed34_m1.load_weights('../input/ubiquantfinalsubmission1/encoder-best1-512_128-seed34_m1.h5')\n",
    "model_512_128_seed34_m2 = build_model_512_128(encoder_1)\n",
    "model_512_128_seed34_m2.load_weights('../input/ubiquantfinalsubmission1/encoder-best1-512_128-seed34_m2.h5')\n",
    "\n",
    "# 全数据model\n",
    "# 0.1535\n",
    "autoencoder, encoder_2 = build_encoder(input_dim)\n",
    "encoder_2.trainable = False\n",
    "autoencoder, encoder_3 = build_encoder(input_dim)\n",
    "encoder_3.trainable = False\n",
    "autoencoder, encoder_4 = build_encoder(input_dim)\n",
    "encoder_4.trainable = False\n",
    "model_0 = build_model_two256drop02(encoder_2)\n",
    "model_0.load_weights('../input/ubiquantfulltrainsubweights/m0-fulltr-two-256-drop0.2-encodrop0.2-ep7-loss0.8171.h5')\n",
    "model_1 = build_model_dropmove(encoder_3)\n",
    "model_1.load_weights('../input/ubiquantfulltrainsubweights/m1-fulltr-256dropmove-encodrop0.2-ep7-loss0.8178.h5')\n",
    "model_2 = build_model_512_128_mish(encoder_4)\n",
    "model_2.load_weights('../input/ubiquantfulltrainsubweights/m2-fulltr-Mish-512_128-512-newenco-ep7-loss0.8178.h5')\n",
    "\n",
    "# conv1d,0.1532\n",
    "conv_models = []\n",
    "for i in range(5):\n",
    "    conv_model = get_conv1d_model()\n",
    "    conv_model.load_weights(f'../input/umpconv1d153/model_{i}.tf')\n",
    "    conv_models.append(conv_model)\n",
    "print(len(conv_models))\n",
    "\n",
    "# 1538\n",
    "conv_models_1 = []\n",
    "for i in range(5):\n",
    "    conv_model = get_conv1d_model()\n",
    "    conv_model.load_weights(f'../input/ubiqunatconv1d21538/model_{i}.tf')\n",
    "    conv_models_1.append(conv_model)\n",
    "print(len(conv_models_1))\n",
    "\n",
    "# 1536\n",
    "conv_models_2 = []\n",
    "for i in range(5):\n",
    "    conv_model = get_conv1d_model_0()\n",
    "    conv_model.load_weights(f'../input/ubiquantconvmish/model_{i}.tf')\n",
    "    conv_models_2.append(conv_model)\n",
    "print(len(conv_models_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb3711d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:41.664792Z",
     "iopub.status.busy": "2022-04-12T08:40:41.664015Z",
     "iopub.status.idle": "2022-04-12T08:40:41.691411Z",
     "shell.execute_reply": "2022-04-12T08:40:41.692268Z",
     "shell.execute_reply.started": "2022-04-12T08:34:40.648195Z"
    },
    "papermill": {
     "duration": 0.098032,
     "end_time": "2022-04-12T08:40:41.692449",
     "exception": false,
     "start_time": "2022-04-12T08:40:41.594417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ubiquant\n",
    "env = ubiquant.make_env()   # initialize the environment\n",
    "iter_test = env.iter_test()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9635870",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:41.837748Z",
     "iopub.status.busy": "2022-04-12T08:40:41.835589Z",
     "iopub.status.idle": "2022-04-12T08:40:41.856641Z",
     "shell.execute_reply": "2022-04-12T08:40:41.857387Z",
     "shell.execute_reply.started": "2022-04-12T08:34:40.670968Z"
    },
    "papermill": {
     "duration": 0.097766,
     "end_time": "2022-04-12T08:40:41.857567",
     "exception": false,
     "start_time": "2022-04-12T08:40:41.759801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_test_dataset(feature, batch_size=2048):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((feature)))\n",
    "    ds = ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c61569ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-12T08:40:41.959961Z",
     "iopub.status.busy": "2022-04-12T08:40:41.958895Z",
     "iopub.status.idle": "2022-04-12T08:40:55.761763Z",
     "shell.execute_reply": "2022-04-12T08:40:55.762303Z",
     "shell.execute_reply.started": "2022-04-12T08:34:40.677421Z"
    },
    "papermill": {
     "duration": 13.866894,
     "end_time": "2022-04-12T08:40:55.762497",
     "exception": false,
     "start_time": "2022-04-12T08:40:41.895603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 08:40:42.409151: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-04-12 08:40:44.129771: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "OK\n",
      "OK\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "w = [0.1537, 0.1536, 0.1537, 0.1533, 0.1532, 0.1532, 0.1538, 0.1543, 0.1538, 0.1534, 0.1530, 0.1536]\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    try:\n",
    "        data_ox = test_df.drop(columns=['row_id', 'investment_id']).values\n",
    "        test_ds = make_test_dataset(data_ox)\n",
    "\n",
    "        t5 = conv_models[0].predict(test_ds, batch_size=2048)\n",
    "        t6 = conv_models_1[0].predict(test_ds, batch_size=2048)\n",
    "        t11 = conv_models_2[0].predict(test_ds)\n",
    "\n",
    "        for i in range(1, 5):\n",
    "            t5 += conv_models[i].predict(test_ds, batch_size=2048)\n",
    "            t6 += conv_models_1[i].predict(test_ds, batch_size=2048)\n",
    "            t11 += conv_models_2[i].predict(test_ds)\n",
    "        t6 = t6 /2.0\n",
    "        t11 = t11/ 2.0\n",
    "        \n",
    "        \n",
    "        data_ox = scaler.transform(data_ox)\n",
    "        test_ds = make_test_dataset(data_ox)\n",
    "\n",
    "        t0 = (model_512_128_m0.predict(test_ds, batch_size=2048) +\n",
    "              model_512_128_m1.predict(test_ds, batch_size=2048))\n",
    "\n",
    "        t1 = (model_384_m1.predict(test_ds, batch_size=2048) +\n",
    "              model_384_m2.predict(test_ds, batch_size=2048))\n",
    "\n",
    "        t7 = (model_dropmove_m0.predict(test_ds, batch_size=2048) +\n",
    "              model_dropmove_m1.predict(test_ds, batch_size=2048) +\n",
    "              model_dropmove_m2.predict(test_ds, batch_size=2048))\n",
    "\n",
    "        t2 = (model_512_256_512_m0.predict(test_ds, batch_size=2048) +\n",
    "              model_512_256_512_m1.predict(test_ds, batch_size=2048) +\n",
    "              model_512_256_512_m2.predict(test_ds, batch_size=2048))\n",
    "\n",
    "        t3 = (model_512_128_512_m0.predict(test_ds, batch_size=2048) +\n",
    "             model_512_128_512_m1.predict(test_ds, batch_size=2048) +\n",
    "             model_512_128_512_m2.predict(test_ds, batch_size=2048))\n",
    "\n",
    "        t4 = (model_0.predict(test_ds, batch_size=2048) +\n",
    "             model_1.predict(test_ds, batch_size=2048) +\n",
    "             model_2.predict(test_ds, batch_size=2048))\n",
    "\n",
    "        t8 = (model_two256drop_m0.predict(test_ds) +\n",
    "             model_two256drop_m1.predict(test_ds) +\n",
    "             model_two256drop_m2.predict(test_ds))\n",
    "\n",
    "        t9 = (model_two128_m0.predict(test_ds) +\n",
    "             model_two128_m1.predict(test_ds) +\n",
    "             model_two128_m2.predict(test_ds))\n",
    "\n",
    "        t10 = (model_512_128_seed34_m0.predict(test_ds) +\n",
    "              model_512_128_seed34_m1.predict(test_ds) +\n",
    "              model_512_128_seed34_m2.predict(test_ds))\n",
    "\n",
    "\n",
    "        target_list = [t0, t1, t2, t3, t4, t5, t6, t7, t8, t9, t10, t11]\n",
    "        model_num = [2.0, 2.0, 3.0, 3.0, 3.0, 5.0, 5.0, 3.0, 3.0, 3.0, 3.0, 5.0]\n",
    "        for i in range(len(target_list)):\n",
    "            target_list[i] = (target_list[i] * 10 / model_num[i] * w[i])\n",
    "        \n",
    "        temp_tar = sum(target_list)\n",
    "        temp_tar[np.isnan(temp_tar)] = 0\n",
    "        sample_prediction_df['target'] = temp_tar\n",
    "        print('OK')\n",
    "        \n",
    "    except Exception:\n",
    "        sample_prediction_df['target'] = np.random.randn(len(sample_prediction_df))\n",
    "\n",
    "    env.predict(sample_prediction_df)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 104.44311,
   "end_time": "2022-04-12T08:40:59.174342",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-12T08:39:14.731232",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
