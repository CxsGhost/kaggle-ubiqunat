{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d118639a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-19T08:18:27.141651Z",
     "iopub.status.busy": "2022-04-19T08:18:27.139404Z",
     "iopub.status.idle": "2022-04-19T08:18:27.152765Z",
     "shell.execute_reply": "2022-04-19T08:18:27.153373Z",
     "shell.execute_reply.started": "2022-04-04T13:03:41.181191Z"
    },
    "papermill": {
     "duration": 0.046459,
     "end_time": "2022-04-19T08:18:27.153706",
     "exception": false,
     "start_time": "2022-04-19T08:18:27.107247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbe2b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:18:27.215841Z",
     "iopub.status.busy": "2022-04-19T08:18:27.215201Z",
     "iopub.status.idle": "2022-04-19T08:18:32.541546Z",
     "shell.execute_reply": "2022-04-19T08:18:32.540605Z",
     "shell.execute_reply.started": "2022-04-04T13:03:41.250196Z"
    },
    "papermill": {
     "duration": 5.360979,
     "end_time": "2022-04-19T08:18:32.541691",
     "exception": false,
     "start_time": "2022-04-19T08:18:27.180712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55f6f9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:18:32.575187Z",
     "iopub.status.busy": "2022-04-19T08:18:32.574426Z",
     "iopub.status.idle": "2022-04-19T08:19:27.289035Z",
     "shell.execute_reply": "2022-04-19T08:19:27.289456Z",
     "shell.execute_reply.started": "2022-04-04T13:03:46.812731Z"
    },
    "papermill": {
     "duration": 54.733516,
     "end_time": "2022-04-19T08:19:27.289649",
     "exception": false,
     "start_time": "2022-04-19T08:18:32.556133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')\n",
    "data = data.drop(columns=['time_id', 'row_id', 'investment_id', 'target']).values\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5d2e43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:27.325264Z",
     "iopub.status.busy": "2022-04-19T08:19:27.324502Z",
     "iopub.status.idle": "2022-04-19T08:19:27.326386Z",
     "shell.execute_reply": "2022-04-19T08:19:27.326777Z",
     "shell.execute_reply.started": "2022-04-04T13:04:43.304712Z"
    },
    "papermill": {
     "duration": 0.021931,
     "end_time": "2022-04-19T08:19:27.326920",
     "exception": false,
     "start_time": "2022-04-19T08:19:27.304989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mish(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Mish, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        return inputs * K.tanh(K.softplus(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1158e7af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:27.364235Z",
     "iopub.status.busy": "2022-04-19T08:19:27.363512Z",
     "iopub.status.idle": "2022-04-19T08:19:27.365906Z",
     "shell.execute_reply": "2022-04-19T08:19:27.365453Z",
     "shell.execute_reply.started": "2022-04-04T13:04:43.314065Z"
    },
    "papermill": {
     "duration": 0.024208,
     "end_time": "2022-04-19T08:19:27.366004",
     "exception": false,
     "start_time": "2022-04-19T08:19:27.341796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = 300\n",
    "def build_encoder(input_dim, noise_rate=0.05):\n",
    "    ori_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    encode = layers.BatchNormalization()(ori_input)\n",
    "    encode = layers.GaussianNoise(stddev=noise_rate)(encode)\n",
    "    encode = layers.Dense(256)(encode)\n",
    "    encode = Mish()(encode)\n",
    "    decode = layers.Dropout(0.2)(encode)\n",
    "    decode = layers.Dense(input_dim, name='decoded')(decode)\n",
    "    x = layers.Dense(265, use_bias=False)(decode)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(1, name='target_out')(x)\n",
    "\n",
    "    encoder = models.Model(inputs=[ori_input], outputs=[encode])\n",
    "    autoencoder = models.Model(inputs=[ori_input], outputs=[decode, x])\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b6bbfac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:27.403527Z",
     "iopub.status.busy": "2022-04-19T08:19:27.402707Z",
     "iopub.status.idle": "2022-04-19T08:19:27.405234Z",
     "shell.execute_reply": "2022-04-19T08:19:27.404793Z"
    },
    "papermill": {
     "duration": 0.024166,
     "end_time": "2022-04-19T08:19:27.405340",
     "exception": false,
     "start_time": "2022-04-19T08:19:27.381174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_encoder_0(input_dim, noise_rate=0.05):\n",
    "    ori_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    encode = layers.BatchNormalization()(ori_input)\n",
    "    encode = layers.GaussianNoise(stddev=noise_rate)(encode)\n",
    "    encode = layers.Dense(256)(encode)\n",
    "    encode = Mish()(encode)\n",
    "    decode = layers.Dropout(0.1)(encode)\n",
    "    decode = layers.Dense(input_dim, name='decoded')(decode)\n",
    "    x = layers.Dense(265, use_bias=False)(decode)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(1, name='target')(x)\n",
    "\n",
    "    encoder = models.Model(inputs=[ori_input], outputs=[encode])\n",
    "    autoencoder = models.Model(inputs=[ori_input], outputs=[decode, x])\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d430e962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:27.444904Z",
     "iopub.status.busy": "2022-04-19T08:19:27.444173Z",
     "iopub.status.idle": "2022-04-19T08:19:27.446409Z",
     "shell.execute_reply": "2022-04-19T08:19:27.446023Z",
     "shell.execute_reply.started": "2022-04-04T13:04:43.325951Z"
    },
    "papermill": {
     "duration": 0.026389,
     "end_time": "2022-04-19T08:19:27.446536",
     "exception": false,
     "start_time": "2022-04-19T08:19:27.420147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_0(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ead3cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:27.485495Z",
     "iopub.status.busy": "2022-04-19T08:19:27.484860Z",
     "iopub.status.idle": "2022-04-19T08:19:27.487393Z",
     "shell.execute_reply": "2022-04-19T08:19:27.486977Z",
     "shell.execute_reply.started": "2022-04-04T13:04:43.340347Z"
    },
    "papermill": {
     "duration": 0.026208,
     "end_time": "2022-04-19T08:19:27.487515",
     "exception": false,
     "start_time": "2022-04-19T08:19:27.461307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_1(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20cb983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:27.526513Z",
     "iopub.status.busy": "2022-04-19T08:19:27.525735Z",
     "iopub.status.idle": "2022-04-19T08:19:27.527735Z",
     "shell.execute_reply": "2022-04-19T08:19:27.528248Z",
     "shell.execute_reply.started": "2022-04-04T13:04:43.35364Z"
    },
    "papermill": {
     "duration": 0.026029,
     "end_time": "2022-04-19T08:19:27.528361",
     "exception": false,
     "start_time": "2022-04-19T08:19:27.502332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_2(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308544f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:27.567671Z",
     "iopub.status.busy": "2022-04-19T08:19:27.566865Z",
     "iopub.status.idle": "2022-04-19T08:19:27.569194Z",
     "shell.execute_reply": "2022-04-19T08:19:27.568790Z"
    },
    "papermill": {
     "duration": 0.026407,
     "end_time": "2022-04-19T08:19:27.569298",
     "exception": false,
     "start_time": "2022-04-19T08:19:27.542891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_bigdrop_1(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e37219f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:27.608575Z",
     "iopub.status.busy": "2022-04-19T08:19:27.607952Z",
     "iopub.status.idle": "2022-04-19T08:19:27.610250Z",
     "shell.execute_reply": "2022-04-19T08:19:27.610670Z"
    },
    "papermill": {
     "duration": 0.026483,
     "end_time": "2022-04-19T08:19:27.610801",
     "exception": false,
     "start_time": "2022-04-19T08:19:27.584318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_bigdrop(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835e3414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:27.644259Z",
     "iopub.status.busy": "2022-04-19T08:19:27.643601Z",
     "iopub.status.idle": "2022-04-19T08:19:27.708895Z",
     "shell.execute_reply": "2022-04-19T08:19:27.708423Z",
     "shell.execute_reply.started": "2022-04-04T13:04:43.367275Z"
    },
    "papermill": {
     "duration": 0.083271,
     "end_time": "2022-04-19T08:19:27.708995",
     "exception": false,
     "start_time": "2022-04-19T08:19:27.625724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ubiquant\n",
    "env = ubiquant.make_env()\n",
    "iter_test = env.iter_test()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0714a9b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:27.745028Z",
     "iopub.status.busy": "2022-04-19T08:19:27.744505Z",
     "iopub.status.idle": "2022-04-19T08:19:36.610291Z",
     "shell.execute_reply": "2022-04-19T08:19:36.611112Z"
    },
    "papermill": {
     "duration": 8.887604,
     "end_time": "2022-04-19T08:19:36.611316",
     "exception": false,
     "start_time": "2022-04-19T08:19:27.723712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 08:19:27.861059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 08:19:27.971042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 08:19:27.971819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 08:19:27.973111: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-19 08:19:27.973522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 08:19:27.974201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 08:19:27.974835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 08:19:29.747456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 08:19:29.748388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 08:19:29.749072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 08:19:29.750640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "weights = ['../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-1-ep8-loss0.8170.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-10-ep8-loss0.8171.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-11-ep8-loss0.8174.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-12-ep8-loss0.8181.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-2-ep8-loss0.8170.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-3-ep8-loss0.8181.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-4-ep8-loss0.8191.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-5-ep8-loss0.8176.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-6-ep8-loss0.8170.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-7-ep8-loss0.8175.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-9-ep8-loss0.8182.h5',\n",
    "          \n",
    "           '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-1-ep8-loss0.8173.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-10-ep8-loss0.8175.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-11-ep8-loss0.8181.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-12-ep8-loss0.8185.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-2-ep8-loss0.8176.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-3-ep8-loss0.8182.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-4-ep8-loss0.8178.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-5-ep8-loss0.8183.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-6-ep8-loss0.8185.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-7-ep8-loss0.8171.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-8-ep8-loss0.8176.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-9-ep8-loss0.8172.h5']\n",
    "\n",
    "model_bigdrop_bt512 = []\n",
    "for w in weights:\n",
    "    autoencoder, encoder = build_encoder_0(input_dim)\n",
    "    encoder.trainable = False\n",
    "    model_temp = build_model_bigdrop(encoder)\n",
    "    model_temp.load_weights(w)\n",
    "    model_bigdrop_bt512.append(model_temp)\n",
    "print(len(model_bigdrop_bt512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "713dfcfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:36.654317Z",
     "iopub.status.busy": "2022-04-19T08:19:36.653408Z",
     "iopub.status.idle": "2022-04-19T08:19:43.421775Z",
     "shell.execute_reply": "2022-04-19T08:19:43.421310Z"
    },
    "papermill": {
     "duration": 6.793378,
     "end_time": "2022-04-19T08:19:43.421902",
     "exception": false,
     "start_time": "2022-04-19T08:19:36.628524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "weights = ['../input/ubiquantbigdropbt1024weights/fulltr-bigdrop-origin-bt1024-test-1-ep9-loss0.8211.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-10-ep9-loss0.8189.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-2-ep9-loss0.8203.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-3-ep9-loss0.8210.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-4-ep9-loss0.8219.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-5-ep9-loss0.8202.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-6-ep9-loss0.8196.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-7-ep9-loss0.8201.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-8-ep9-loss0.8198.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-9-ep9-loss0.8196.h5',\n",
    "           \n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-1-ep9-loss0.8200.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-10-ep9-loss0.8206.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-11-ep9-loss0.8205.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-12-ep9-loss0.8193.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-13-ep9-loss0.8211.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-14-ep9-loss0.8209.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-2-ep9-loss0.8217.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-3-ep9-loss0.8200.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-4-ep9-loss0.8191.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-5-ep9-loss0.8198.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-6-ep9-loss0.8203.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-7-ep9-loss0.8195.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-8-ep9-loss0.8198.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-9-ep9-loss0.8200.h5']\n",
    "\n",
    "model_bigdrop_bt1024 = []\n",
    "for w in weights:\n",
    "    autoencoder, encoder = build_encoder_0(input_dim)\n",
    "    encoder.trainable = False\n",
    "    model_temp = build_model_bigdrop(encoder)\n",
    "    model_temp.load_weights(w)\n",
    "    model_bigdrop_bt1024.append(model_temp)\n",
    "print(len(model_bigdrop_bt1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f959b178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:43.463824Z",
     "iopub.status.busy": "2022-04-19T08:19:43.463131Z",
     "iopub.status.idle": "2022-04-19T08:19:50.461865Z",
     "shell.execute_reply": "2022-04-19T08:19:50.462556Z"
    },
    "papermill": {
     "duration": 7.024385,
     "end_time": "2022-04-19T08:19:50.462717",
     "exception": false,
     "start_time": "2022-04-19T08:19:43.438332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "weights = ['../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-1-ep9-loss0.8195.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-10-ep9-loss0.8197.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-11-ep9-loss0.8204.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-12-ep9-loss0.8198.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-13-ep9-loss0.8210.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-14-ep9-loss0.8192.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-15-ep9-loss0.8188.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-16-ep9-loss0.8202.h5',\n",
    "#           '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-17-ep9-loss0.8217.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-18-ep9-loss0.8198.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-19-ep9-loss0.8206.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-2-ep9-loss0.8202.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-20-ep9-loss0.8193.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-21-ep9-loss0.8201.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-22-ep9-loss0.8200.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-23-ep9-loss0.8195.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-24-ep9-loss0.8213.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-25-ep9-loss0.8190.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-3-ep9-loss0.8199.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-4-ep9-loss0.8200.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-5-ep9-loss0.8212.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-6-ep9-loss0.8199.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-7-ep9-loss0.8206.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-9-ep9-loss0.8190.h5']\n",
    "\n",
    "model_bigdrop_1_bt1024 = []\n",
    "for w in weights:\n",
    "    autoencoder, encoder = build_encoder_0(input_dim)\n",
    "    encoder.trainable = False\n",
    "    model_temp = build_model_bigdrop_1(encoder)\n",
    "    model_temp.load_weights(w)\n",
    "    model_bigdrop_1_bt1024.append(model_temp)\n",
    "print(len(model_bigdrop_1_bt1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f175fdf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:50.506723Z",
     "iopub.status.busy": "2022-04-19T08:19:50.506094Z",
     "iopub.status.idle": "2022-04-19T08:19:51.906716Z",
     "shell.execute_reply": "2022-04-19T08:19:51.907193Z"
    },
    "papermill": {
     "duration": 1.426293,
     "end_time": "2022-04-19T08:19:51.907352",
     "exception": false,
     "start_time": "2022-04-19T08:19:50.481059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "weights = ['../input/ubiquanttts6foldweights/origin-bigdrop-test-1_5.h5',\n",
    "          '../input/ubiquanttts6foldweights/origin-bigdrop-test-2_5.h5',\n",
    "          '../input/ubiquanttts6foldweights/origin-bigdrop-test-3_5.h5',\n",
    "          '../input/ubiquanttts6foldweights/origin-bigdrop-test-4_5.h5']\n",
    "\n",
    "model_bigdrop_fold6 = []\n",
    "\n",
    "autoencoder, encoder = build_encoder_0(input_dim)\n",
    "encoder.trainable = False\n",
    "model_temp = build_model_bigdrop_1(encoder)\n",
    "model_temp.load_weights('../input/ubiquanttts6foldweights/origin-bigdrop-1-test-1_5.h5')\n",
    "model_bigdrop_fold6.append(model_temp)\n",
    "\n",
    "for w in weights:\n",
    "    autoencoder, encoder = build_encoder_0(input_dim)\n",
    "    encoder.trainable = False\n",
    "    model_temp = build_model_bigdrop(encoder)\n",
    "    model_temp.load_weights(w)\n",
    "    model_bigdrop_fold6.append(model_temp)\n",
    "print(len(model_bigdrop_fold6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b88e417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:51.950883Z",
     "iopub.status.busy": "2022-04-19T08:19:51.949916Z",
     "iopub.status.idle": "2022-04-19T08:19:54.117375Z",
     "shell.execute_reply": "2022-04-19T08:19:54.116712Z"
    },
    "papermill": {
     "duration": 2.193157,
     "end_time": "2022-04-19T08:19:54.117556",
     "exception": false,
     "start_time": "2022-04-19T08:19:51.924399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "weights = ['../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-1_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-2_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-3_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-4_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-5_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-6_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-7_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-8_13.h5']\n",
    "\n",
    "model_bigdrop_fold14 = []\n",
    "for w in weights:\n",
    "    autoencoder, encoder = build_encoder_0(input_dim)\n",
    "    encoder.trainable = False\n",
    "    model_temp = build_model_bigdrop(encoder)\n",
    "    model_temp.load_weights(w)\n",
    "    model_bigdrop_fold14.append(model_temp)\n",
    "print(len(model_bigdrop_fold14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9ceb946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:54.165098Z",
     "iopub.status.busy": "2022-04-19T08:19:54.164259Z",
     "iopub.status.idle": "2022-04-19T08:19:54.777713Z",
     "shell.execute_reply": "2022-04-19T08:19:54.777120Z",
     "shell.execute_reply.started": "2022-04-04T13:04:43.404641Z"
    },
    "papermill": {
     "duration": 0.641037,
     "end_time": "2022-04-19T08:19:54.777847",
     "exception": false,
     "start_time": "2022-04-19T08:19:54.136810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder, encoder_0 = build_encoder(input_dim)\n",
    "encoder_0.trainable = False\n",
    "autoencoder, encoder_1 = build_encoder(input_dim)\n",
    "encoder_1.trainable = False\n",
    "autoencoder, encoder_2 = build_encoder(input_dim)\n",
    "encoder_2.trainable = False\n",
    "\n",
    "autoencoder, encoder_0_0 = build_encoder(input_dim)\n",
    "encoder_0_0.trainable = False\n",
    "autoencoder, encoder_0_2 = build_encoder(input_dim)\n",
    "encoder_0_2.trainable = False\n",
    "\n",
    "autoencoder, encoder_1_0 = build_encoder(input_dim)\n",
    "encoder_1_0.trainable = False\n",
    "\n",
    "autoencoder, encoder_2_0 = build_encoder(input_dim)\n",
    "encoder_2_0.trainable = False\n",
    "autoencoder, encoder_2_1 = build_encoder(input_dim)\n",
    "encoder_2_1.trainable = False\n",
    "autoencoder, encoder_2_2 = build_encoder(input_dim)\n",
    "encoder_2_2.trainable = False\n",
    "autoencoder, encoder_2_3 = build_encoder(input_dim)\n",
    "encoder_2_3.trainable = False\n",
    "autoencoder, encoder_2_4 = build_encoder(input_dim)\n",
    "encoder_2_4.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a23a4da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:54.827014Z",
     "iopub.status.busy": "2022-04-19T08:19:54.823505Z",
     "iopub.status.idle": "2022-04-19T08:19:57.506742Z",
     "shell.execute_reply": "2022-04-19T08:19:57.507245Z",
     "shell.execute_reply.started": "2022-04-04T13:04:46.332811Z"
    },
    "papermill": {
     "duration": 2.710525,
     "end_time": "2022-04-19T08:19:57.507406",
     "exception": false,
     "start_time": "2022-04-19T08:19:54.796881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#0.1521\n",
    "model_0 = build_model_0(encoder_0)\n",
    "model_0.load_weights('../input/ubiquantfulltrainsubweights/m0-fulltr-two-256-drop0.2-encodrop0.2-ep7-loss0.8171.h5')\n",
    "#0.1515\n",
    "model_0_0= build_model_0(encoder_0_0)\n",
    "model_0_0.load_weights('../input/ubiquantfulltrainsubweights/m0_0-0.1515-fulltr-two256drop-seed-1-test-3-ep7-loss0.8170.h5')\n",
    "#1532\n",
    "model_0_2= build_model_0(encoder_0_2)\n",
    "model_0_2.load_weights('../input/ubiquantfulltrainsubweights/m0_2_fulltr-two256drop-myloss-4-6-test-1-ep7-loss0.8179.h5')\n",
    "\n",
    "\n",
    "#1521-ep7\n",
    "model_1 = build_model_1(encoder_1)\n",
    "model_1.load_weights('../input/ubiquantfulltrainsubweights/m1-fulltr-256dropmove-encodrop0.2-ep7-loss0.8178.h5')\n",
    "#1520\n",
    "model_1_0 = build_model_1(encoder_1_0)\n",
    "model_1_0.load_weights('../input/ubiquantfulltrainsubweights/m1_0_fulltr-dropmove-myloss-4-6-test-1-ep7-loss0.8170.h5')\n",
    "\n",
    "#1523\n",
    "model_2 = build_model_2(encoder_2)\n",
    "model_2.load_weights('../input/ubiquantfulltrainsubweights/m2-fulltr-Mish-512_128-512-newenco-ep7-loss0.8178.h5')\n",
    "#1501\n",
    "model_2_0 = build_model_2(encoder_2_0)\n",
    "model_2_0.load_weights('../input/ubiquantfulltrainsubweights/m2_0_fulltr-origin-seed-1-test-3-ep7-loss0.8171.h5')\n",
    "#1514\n",
    "model_2_1 = build_model_2(encoder_2_1)\n",
    "model_2_1.load_weights('../input/ubiquantfulltrainsubweights/m2_1_fulltr-tfrecords-original-test-1-ep7-loss0.8189.h5')\n",
    "#1511\n",
    "model_2_2 = build_model_2(encoder_2_2)\n",
    "model_2_2.load_weights('../input/ubiquantfulltrainsubweights/m2_2_fulltr-origin-seed430-test-1-ep7-loss0.8179.h5')\n",
    "#1504\n",
    "model_2_3 = build_model_2(encoder_2_3)\n",
    "model_2_3.load_weights('../input/ubiquantfulltrainsubweights/m2_3_fulltr-origin-seed72-test-1-ep7-loss0.8176.h5')\n",
    "#1516\n",
    "model_2_4 = build_model_2(encoder_2_4)\n",
    "model_2_4.load_weights('../input/ubiquantfulltrainsubweights/m2_4_fulltr-tfrecords-origin-test-3-ep7-loss0.8170.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "592c237e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:57.551702Z",
     "iopub.status.busy": "2022-04-19T08:19:57.550955Z",
     "iopub.status.idle": "2022-04-19T08:19:57.553365Z",
     "shell.execute_reply": "2022-04-19T08:19:57.553877Z",
     "shell.execute_reply.started": "2022-04-04T13:04:48.117169Z"
    },
    "papermill": {
     "duration": 0.02694,
     "end_time": "2022-04-19T08:19:57.554008",
     "exception": false,
     "start_time": "2022-04-19T08:19:57.527068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_test_dataset(feature, batch_size=2048):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((feature)))\n",
    "    ds = ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4abb32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T08:19:57.607980Z",
     "iopub.status.busy": "2022-04-19T08:19:57.607399Z",
     "iopub.status.idle": "2022-04-19T08:20:14.092063Z",
     "shell.execute_reply": "2022-04-19T08:20:14.092470Z",
     "shell.execute_reply.started": "2022-04-04T13:04:48.13046Z"
    },
    "papermill": {
     "duration": 16.519592,
     "end_time": "2022-04-19T08:20:14.092656",
     "exception": false,
     "start_time": "2022-04-19T08:19:57.573064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 08:19:57.857780: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    try:\n",
    "        data_ox = test_df.drop(columns=['row_id', 'investment_id']).values\n",
    "        data_ox = scaler.transform(data_ox)\n",
    "        data_ox = make_test_dataset(data_ox)\n",
    "\n",
    "        t0 = (model_0.predict(data_ox) * 1.521 +\n",
    "              model_0_0.predict(data_ox) * 1.515 +\n",
    "             model_0_2.predict(data_ox) * 1.532 +\n",
    "             model_1.predict(data_ox) * 1.521 +\n",
    "             model_1_0.predict(data_ox) * 1.520 +\n",
    "             model_2.predict(data_ox) * 1.523 +\n",
    "             model_2_0.predict(data_ox) * 1.501 +\n",
    "             model_2_1.predict(data_ox) * 1.514 +\n",
    "             model_2_2.predict(data_ox) * 1.511 +\n",
    "             model_2_4.predict(data_ox) * 1.516) \n",
    "        t0[np.isnan(t0)] = 0\n",
    "        t0 = t0 / 15.0\n",
    "        \n",
    "        t1 = model_bigdrop_bt512[0].predict(data_ox)\n",
    "        for i in range(1, len(model_bigdrop_bt512)):\n",
    "            t1 = t1 + model_bigdrop_bt512[i].predict(data_ox)\n",
    "        t1[np.isnan(t1)] = 0\n",
    "        t1 = t1 / len(model_bigdrop_bt512)\n",
    "\n",
    "        t2 = model_bigdrop_bt1024[0].predict(data_ox)\n",
    "        for i in range(1, len(model_bigdrop_bt1024)):\n",
    "            t2 = t2 + model_bigdrop_bt1024[i].predict(data_ox)\n",
    "        t2[np.isnan(t2)] = 0\n",
    "        t2 = t2 / len(model_bigdrop_bt1024)\n",
    "\n",
    "        t3 = model_bigdrop_1_bt1024[0].predict(data_ox)\n",
    "        for i in range(1, len(model_bigdrop_1_bt1024)):\n",
    "            t3 = t3 + model_bigdrop_1_bt1024[i].predict(data_ox)\n",
    "        t3[np.isnan(t3)] = 0\n",
    "        t3 = t3 / len(model_bigdrop_1_bt1024)\n",
    "        \n",
    "        t4 = model_bigdrop_fold6[0].predict(data_ox)\n",
    "        for i in range(1, len(model_bigdrop_fold6)):\n",
    "            t4 = t4 + model_bigdrop_fold6[i].predict(data_ox)\n",
    "        t4[np.isnan(t4)] = 0\n",
    "        t4 = t4 / len(model_bigdrop_fold6)\n",
    "        \n",
    "        t5 = model_bigdrop_fold14[0].predict(data_ox)\n",
    "        for i in range(1, len(model_bigdrop_fold14)):\n",
    "            t5 = t5 + model_bigdrop_fold14[i].predict(data_ox)\n",
    "        t5[np.isnan(t5)] = 0\n",
    "        t5 = t5 / len(model_bigdrop_fold14)\n",
    "\n",
    "\n",
    "        sample_prediction_df['target'] = (t0 + t1 + t2 + t3) / 4.0 * 0.65 + t4 * 0.125 + t5 * 0.225 \n",
    "\n",
    "    except Exception:\n",
    "        sample_prediction_df['target'] = np.random.randn(len(sample_prediction_df))\n",
    "    \n",
    "    env.predict(sample_prediction_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 118.334447,
   "end_time": "2022-04-19T08:20:17.398134",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-19T08:18:19.063687",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
