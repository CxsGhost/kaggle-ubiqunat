{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2752e991",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:04.194172Z",
     "iopub.status.busy": "2022-04-14T02:38:04.192419Z",
     "iopub.status.idle": "2022-04-14T02:38:04.204570Z",
     "shell.execute_reply": "2022-04-14T02:38:04.203983Z",
     "shell.execute_reply.started": "2022-03-28T02:53:03.96307Z"
    },
    "papermill": {
     "duration": 0.040932,
     "end_time": "2022-04-14T02:38:04.204712",
     "exception": false,
     "start_time": "2022-04-14T02:38:04.163780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31a37b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:04.242811Z",
     "iopub.status.busy": "2022-04-14T02:38:04.241858Z",
     "iopub.status.idle": "2022-04-14T02:38:04.243826Z",
     "shell.execute_reply": "2022-04-14T02:38:04.244401Z",
     "shell.execute_reply.started": "2022-03-28T02:53:04.004024Z"
    },
    "papermill": {
     "duration": 0.024334,
     "end_time": "2022-04-14T02:38:04.244538",
     "exception": false,
     "start_time": "2022-04-14T02:38:04.220204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    fea_dir = '../input/ubiquant-train-data/train_std_data.npy'\n",
    "    target_dir = '../input/ubiquant-train-data/train_(timeid)target-f32.npy'\n",
    "    tfrecords_dir = '../input/ubiquant-train-data/train_data_target-f32-all.tfrecords'\n",
    "    time_dir = None\n",
    "    inv_dir = None\n",
    "\n",
    "    input_dim = 300\n",
    "    enco_noise_rate = 0.05\n",
    "    \n",
    "    full_train = True\n",
    "    \n",
    "    just_train_enco = False\n",
    "    freeze_enco = False\n",
    "    enco_weights_dir = '../input/encoderonly-feaall-data/cur-best-encoder.h5'\n",
    "    \n",
    "    mlp_batch_size = 512\n",
    "    enco_batch_size = 512\n",
    "    test_batch_size = 4096\n",
    "    train_shuffle_seed = 113\n",
    "    \n",
    "    split_n = 6\n",
    "    use_time_kfold = True\n",
    "    t_kfold_start = 4\n",
    "    simple_kfold_get = 2\n",
    "    simple_kfold_seed = 125\n",
    "\n",
    "    mlp_LR = 0.001\n",
    "    enco_LR = 0.001\n",
    "\n",
    "    cb_monitor = 'val_loss'\n",
    "    cb_rlrp_patience = 8\n",
    "    cb_rlrp_factor = 0.6\n",
    "    cb_es_patience = 15\n",
    "    \n",
    "    mlp_epoch = 12\n",
    "    enco_epoch = 105\n",
    "    \n",
    "    fulltr_savedir = './fulltr-bigdrop-origin-bt512-test-1-ep{epoch}-loss{loss:.4f}.h5'\n",
    "\n",
    "    def save_mlp_dir(self, the_fold):\n",
    "        return './origin-bigdrop-test-1_{0}.h5'.format(the_fold)\n",
    "\n",
    "    def save_encoder_dir(self):\n",
    "        return './fulltr-enco256256-{0}.h5'.format('full-train-unfreeze-1')\n",
    "\n",
    "cfg = CFG()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "650cdc2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:04.278081Z",
     "iopub.status.busy": "2022-04-14T02:38:04.277405Z",
     "iopub.status.idle": "2022-04-14T02:38:09.688873Z",
     "shell.execute_reply": "2022-04-14T02:38:09.688343Z",
     "shell.execute_reply.started": "2022-03-28T02:53:04.017734Z"
    },
    "papermill": {
     "duration": 5.431215,
     "end_time": "2022-04-14T02:38:09.689006",
     "exception": false,
     "start_time": "2022-04-14T02:38:04.257791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964a0191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:09.718415Z",
     "iopub.status.busy": "2022-04-14T02:38:09.717894Z",
     "iopub.status.idle": "2022-04-14T02:38:28.262331Z",
     "shell.execute_reply": "2022-04-14T02:38:28.261558Z",
     "shell.execute_reply.started": "2022-03-28T02:53:09.768437Z"
    },
    "papermill": {
     "duration": 18.561704,
     "end_time": "2022-04-14T02:38:28.262460",
     "exception": false,
     "start_time": "2022-04-14T02:38:09.700756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3141410, 300) float16\n",
      "(3141410, 2) float32\n"
     ]
    }
   ],
   "source": [
    "# if not cfg.full_train:\n",
    "fea_data = np.load(cfg.fea_dir)\n",
    "target = np.load(cfg.target_dir)\n",
    "print(fea_data.shape, fea_data.dtype)\n",
    "print(target.shape, target.dtype)\n",
    "\n",
    "if cfg.time_dir is not None:\n",
    "    time_id = np.load(cfg.time_dir)\n",
    "if cfg.inv_dir is not None:\n",
    "    inv_id = np.load(cfg.inv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c273a67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:28.293679Z",
     "iopub.status.busy": "2022-04-14T02:38:28.292107Z",
     "iopub.status.idle": "2022-04-14T02:38:28.294286Z",
     "shell.execute_reply": "2022-04-14T02:38:28.294669Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.229505Z"
    },
    "papermill": {
     "duration": 0.019424,
     "end_time": "2022-04-14T02:38:28.294823",
     "exception": false,
     "start_time": "2022-04-14T02:38:28.275399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mish(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Mish, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        return inputs * K.tanh(K.softplus(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e07c1dfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:28.324381Z",
     "iopub.status.busy": "2022-04-14T02:38:28.323754Z",
     "iopub.status.idle": "2022-04-14T02:38:28.326345Z",
     "shell.execute_reply": "2022-04-14T02:38:28.326717Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.240449Z"
    },
    "papermill": {
     "duration": 0.0204,
     "end_time": "2022-04-14T02:38:28.326872",
     "exception": false,
     "start_time": "2022-04-14T02:38:28.306472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PearsonCorrelation(y_true, y_pred):\n",
    "    yt_mean = K.mean(y_true)\n",
    "    yp_mean = K.mean(y_pred)\n",
    "    cor = K.mean((y_true - yt_mean) * (y_pred - yp_mean))\n",
    "    yt_std = K.std(y_true)\n",
    "    yp_std = K.std(y_pred)\n",
    "    pearson = cor / (yt_std * yp_std)\n",
    "    return pearson\n",
    "\n",
    "def PearsonCorrelationLoss(y_true, y_pred):\n",
    "    return K.constant(1.0, dtype=y_pred.dtype) - PearsonCorrelation(y_true, y_pred)\n",
    "\n",
    "def MyLoss(y_true, y_pred):\n",
    "    return losses.mean_squared_error(y_true, y_pred) * 0.5 + PearsonCorrelationLoss(y_true, y_pred) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c04db23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:28.358936Z",
     "iopub.status.busy": "2022-04-14T02:38:28.358371Z",
     "iopub.status.idle": "2022-04-14T02:38:28.361478Z",
     "shell.execute_reply": "2022-04-14T02:38:28.361079Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.249353Z"
    },
    "papermill": {
     "duration": 0.022989,
     "end_time": "2022-04-14T02:38:28.361581",
     "exception": false,
     "start_time": "2022-04-14T02:38:28.338592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_encoder(input_dim, noise_rate=0.05):\n",
    "    ori_input = Input(shape=(input_dim,), dtype='float16')\n",
    "    encode = layers.BatchNormalization()(ori_input)\n",
    "    encode = layers.GaussianNoise(stddev=noise_rate)(encode)\n",
    "    encode = layers.Dense(256)(encode)\n",
    "    encode = Mish()(encode)\n",
    "    decode = layers.Dropout(0.1)(encode)\n",
    "    decode = layers.Dense(input_dim, name='decoded')(decode)\n",
    "    x = layers.Dense(265, use_bias=False)(decode)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(1, name='target')(x)\n",
    "\n",
    "    encoder = models.Model(inputs=[ori_input], outputs=[encode])\n",
    "    autoencoder = models.Model(inputs=[ori_input], outputs=[decode, x])\n",
    "    autoencoder.compile(optimizer=optimizers.Adam(learning_rate=cfg.enco_LR),\n",
    "                        loss={'decoded': losses.MeanSquaredError(),\n",
    "                              'target': losses.MeanSquaredError()},\n",
    "                        metrics={'target': PearsonCorrelation})\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de968efd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:28.396116Z",
     "iopub.status.busy": "2022-04-14T02:38:28.395529Z",
     "iopub.status.idle": "2022-04-14T02:38:28.399149Z",
     "shell.execute_reply": "2022-04-14T02:38:28.398726Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.260692Z"
    },
    "papermill": {
     "duration": 0.025702,
     "end_time": "2022-04-14T02:38:28.399251",
     "exception": false,
     "start_time": "2022-04-14T02:38:28.373549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(encoder):\n",
    "    ox_input = Input(shape=(cfg.input_dim,), dtype='float16')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=cfg.mlp_LR),\n",
    "                  loss=losses.MeanSquaredError(),\n",
    "                  metrics=[PearsonCorrelation])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d591cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:28.427213Z",
     "iopub.status.busy": "2022-04-14T02:38:28.425644Z",
     "iopub.status.idle": "2022-04-14T02:38:28.427812Z",
     "shell.execute_reply": "2022-04-14T02:38:28.428233Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.276612Z"
    },
    "papermill": {
     "duration": 0.017584,
     "end_time": "2022-04-14T02:38:28.428346",
     "exception": false,
     "start_time": "2022-04-14T02:38:28.410762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def see_model_config(my_model):\n",
    "    print(my_model.summary())\n",
    "    plot_model(my_model, './the_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "387db8d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:28.459136Z",
     "iopub.status.busy": "2022-04-14T02:38:28.458291Z",
     "iopub.status.idle": "2022-04-14T02:38:28.460606Z",
     "shell.execute_reply": "2022-04-14T02:38:28.461041Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.285625Z"
    },
    "papermill": {
     "duration": 0.02114,
     "end_time": "2022-04-14T02:38:28.461160",
     "exception": false,
     "start_time": "2022-04-14T02:38:28.440020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metrics_ave_time_id(y_true, y_pred):\n",
    "    person_list = []\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = y_pred.flatten()\n",
    "    time_id = y_true[:, 0]\n",
    "    y_true = y_true[:, 1]\n",
    "    for t in np.unique(time_id):\n",
    "        y_t = y_true[time_id == t]\n",
    "        if y_t.shape[0] == 1:\n",
    "            continue\n",
    "        y_p = y_pred[time_id == t]\n",
    "        y_t_mean = np.average(y_t)\n",
    "        y_p_mean = np.average(y_p)\n",
    "        cov = np.average((y_t - y_t_mean) * (y_p - y_p_mean))\n",
    "        y_t_std = np.std(y_t)\n",
    "        y_p_std = np.std(y_p)\n",
    "        person_list.append(cov / (y_t_std * y_p_std + 1e-5))\n",
    "    person_list = np.array(person_list)\n",
    "    return np.average(person_list), np.average(person_list[person_list >= 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0e218d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:28.489852Z",
     "iopub.status.busy": "2022-04-14T02:38:28.489078Z",
     "iopub.status.idle": "2022-04-14T02:38:28.491518Z",
     "shell.execute_reply": "2022-04-14T02:38:28.491103Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.296448Z"
    },
    "papermill": {
     "duration": 0.018985,
     "end_time": "2022-04-14T02:38:28.491616",
     "exception": false,
     "start_time": "2022-04-14T02:38:28.472631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataset(feature, y, batch_size=512, mode=\"train\", to='mlp'):\n",
    "    if to == 'mlp':\n",
    "        ds = tf.data.Dataset.from_tensor_slices((feature, y))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((feature, (feature, y)))\n",
    "    if mode == \"train\":\n",
    "        ds = ds.shuffle(4096, seed=cfg.train_shuffle_seed, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57390fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:28.522553Z",
     "iopub.status.busy": "2022-04-14T02:38:28.521815Z",
     "iopub.status.idle": "2022-04-14T02:38:28.525550Z",
     "shell.execute_reply": "2022-04-14T02:38:28.525113Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.304874Z"
    },
    "papermill": {
     "duration": 0.022613,
     "end_time": "2022-04-14T02:38:28.525650",
     "exception": false,
     "start_time": "2022-04-14T02:38:28.503037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_function(record_bytes):\n",
    "    return tf.io.parse_single_example(record_bytes,\n",
    "                                      {\"feature\": tf.io.FixedLenFeature([300], dtype=tf.float32),\n",
    "                                        \"target\": tf.io.FixedLenFeature([], dtype=tf.float32)})\n",
    "\n",
    "def preprocess_mlp(item):\n",
    "    return (item[\"feature\"]), item[\"target\"]\n",
    "\n",
    "def preprocess_enco(item):\n",
    "    return (item[\"feature\"]), (item['feature'], item[\"target\"])\n",
    "\n",
    "def make_fulltr_dataset(file_path, batch_size=512, to='mlp'):\n",
    "    ds = tf.data.TFRecordDataset(file_path)\n",
    "    ds = ds.map(decode_function)\n",
    "    if to == 'mlp':\n",
    "        ds = ds.map(preprocess_mlp)\n",
    "    else:\n",
    "        ds = ds.map(preprocess_enco)\n",
    "    ds = ds.shuffle(4096, seed=cfg.train_shuffle_seed, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d359c78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:28.555989Z",
     "iopub.status.busy": "2022-04-14T02:38:28.555244Z",
     "iopub.status.idle": "2022-04-14T02:38:28.557598Z",
     "shell.execute_reply": "2022-04-14T02:38:28.557182Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.316775Z"
    },
    "papermill": {
     "duration": 0.020502,
     "end_time": "2022-04-14T02:38:28.557694",
     "exception": false,
     "start_time": "2022-04-14T02:38:28.537192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_encoder(mode='new', train_ds=None, test_ds=None, the_callback=None):\n",
    "    if mode == 'freeze':\n",
    "        autoencoder, encoder = build_encoder(cfg.input_dim)\n",
    "        encoder.load_weights(cfg.enco_weights_dir)\n",
    "    else:\n",
    "        assert the_callback != None, 'callbacks 不能是 None!'\n",
    "        autoencoder, encoder = build_encoder(cfg.input_dim, noise_rate=cfg.enco_noise_rate)\n",
    "        print(encoder.summary())\n",
    "        if mode == 'new':\n",
    "            autoencoder.fit(train_ds,\n",
    "                            epochs=cfg.enco_epoch,\n",
    "                            callbacks=the_callback)\n",
    "            encoder.save_weights(cfg.save_encoder_dir())\n",
    "        elif mode == 'cv':\n",
    "                autoencoder.fit(train_ds,\n",
    "                                validation_data=test_ds,\n",
    "                                epochs=cfg.enco_epoch,\n",
    "                                callbacks=the_callback,\n",
    "                                verbose=2)\n",
    "    encoder.trainable = False\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abfbd8e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T02:38:28.774784Z",
     "iopub.status.busy": "2022-04-14T02:38:28.773798Z",
     "iopub.status.idle": "2022-04-14T03:55:05.068103Z",
     "shell.execute_reply": "2022-04-14T03:55:05.068505Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.326963Z"
    },
    "papermill": {
     "duration": 4596.499038,
     "end_time": "2022-04-14T03:55:05.068680",
     "exception": false,
     "start_time": "2022-04-14T02:38:28.569642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 02:38:28.660634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:38:28.770249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:38:28.771050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:38:28.773975: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-14 02:38:28.775084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:38:28.775999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:38:28.776868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:38:30.604861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:38:30.605680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:38:30.606367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-14 02:38:30.606983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-04-14 02:38:32.132055: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1884846000 exceeds 10% of free system memory.\n",
      "2022-04-14 02:38:35.769466: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1884846000 exceeds 10% of free system memory.\n",
      "2022-04-14 02:38:37.666725: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1884846000 exceeds 10% of free system memory.\n",
      "2022-04-14 02:38:39.108447: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1884846000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               77056     \n",
      "_________________________________________________________________\n",
      "mish (Mish)                  (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 78,256\n",
      "Trainable params: 77,656\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 02:38:40.867307: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1884846000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 02:38:46.574252: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136/6136 [==============================] - 36s 5ms/step - loss: 1.0874 - decoded_loss: 0.2593 - target_loss: 0.8281 - target_PearsonCorrelation: 0.1808\n",
      "Epoch 2/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9825 - decoded_loss: 0.1691 - target_loss: 0.8134 - target_PearsonCorrelation: 0.1937\n",
      "Epoch 3/105\n",
      "6136/6136 [==============================] - 34s 5ms/step - loss: 0.9772 - decoded_loss: 0.1635 - target_loss: 0.8137 - target_PearsonCorrelation: 0.1931\n",
      "Epoch 4/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9748 - decoded_loss: 0.1617 - target_loss: 0.8131 - target_PearsonCorrelation: 0.1941\n",
      "Epoch 5/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9732 - decoded_loss: 0.1609 - target_loss: 0.8123 - target_PearsonCorrelation: 0.1962\n",
      "Epoch 6/105\n",
      "6136/6136 [==============================] - 35s 6ms/step - loss: 0.9725 - decoded_loss: 0.1603 - target_loss: 0.8122 - target_PearsonCorrelation: 0.1967\n",
      "Epoch 7/105\n",
      "6136/6136 [==============================] - 34s 5ms/step - loss: 0.9719 - decoded_loss: 0.1600 - target_loss: 0.8119 - target_PearsonCorrelation: 0.1971\n",
      "Epoch 8/105\n",
      "6136/6136 [==============================] - 35s 6ms/step - loss: 0.9719 - decoded_loss: 0.1599 - target_loss: 0.8120 - target_PearsonCorrelation: 0.1970\n",
      "Epoch 9/105\n",
      "6136/6136 [==============================] - 35s 6ms/step - loss: 0.9715 - decoded_loss: 0.1598 - target_loss: 0.8117 - target_PearsonCorrelation: 0.1978\n",
      "Epoch 10/105\n",
      "6136/6136 [==============================] - 35s 6ms/step - loss: 0.9715 - decoded_loss: 0.1598 - target_loss: 0.8117 - target_PearsonCorrelation: 0.1976\n",
      "Epoch 11/105\n",
      "6136/6136 [==============================] - 34s 5ms/step - loss: 0.9718 - decoded_loss: 0.1600 - target_loss: 0.8118 - target_PearsonCorrelation: 0.1975\n",
      "Epoch 12/105\n",
      "6136/6136 [==============================] - 35s 6ms/step - loss: 0.9719 - decoded_loss: 0.1601 - target_loss: 0.8118 - target_PearsonCorrelation: 0.1977\n",
      "Epoch 13/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9716 - decoded_loss: 0.1600 - target_loss: 0.8116 - target_PearsonCorrelation: 0.1983\n",
      "Epoch 14/105\n",
      "6136/6136 [==============================] - 36s 6ms/step - loss: 0.9717 - decoded_loss: 0.1600 - target_loss: 0.8117 - target_PearsonCorrelation: 0.1980\n",
      "Epoch 15/105\n",
      "6136/6136 [==============================] - 34s 5ms/step - loss: 0.9720 - decoded_loss: 0.1603 - target_loss: 0.8118 - target_PearsonCorrelation: 0.1976\n",
      "Epoch 16/105\n",
      "6136/6136 [==============================] - 36s 6ms/step - loss: 0.9720 - decoded_loss: 0.1604 - target_loss: 0.8116 - target_PearsonCorrelation: 0.1981\n",
      "Epoch 17/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9715 - decoded_loss: 0.1602 - target_loss: 0.8114 - target_PearsonCorrelation: 0.1988\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005500000261235982.\n",
      "Epoch 18/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9685 - decoded_loss: 0.1529 - target_loss: 0.8156 - target_PearsonCorrelation: 0.1866\n",
      "Epoch 19/105\n",
      "6136/6136 [==============================] - 36s 6ms/step - loss: 0.9664 - decoded_loss: 0.1513 - target_loss: 0.8152 - target_PearsonCorrelation: 0.1880\n",
      "Epoch 20/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9660 - decoded_loss: 0.1511 - target_loss: 0.8150 - target_PearsonCorrelation: 0.1885\n",
      "Epoch 21/105\n",
      "6136/6136 [==============================] - 36s 6ms/step - loss: 0.9657 - decoded_loss: 0.1508 - target_loss: 0.8149 - target_PearsonCorrelation: 0.1889\n",
      "Epoch 22/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9656 - decoded_loss: 0.1507 - target_loss: 0.8149 - target_PearsonCorrelation: 0.1890\n",
      "Epoch 23/105\n",
      "6136/6136 [==============================] - 35s 6ms/step - loss: 0.9652 - decoded_loss: 0.1505 - target_loss: 0.8146 - target_PearsonCorrelation: 0.1897\n",
      "Epoch 24/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9653 - decoded_loss: 0.1505 - target_loss: 0.8148 - target_PearsonCorrelation: 0.1888\n",
      "Epoch 25/105\n",
      "6136/6136 [==============================] - 37s 6ms/step - loss: 0.9650 - decoded_loss: 0.1503 - target_loss: 0.8146 - target_PearsonCorrelation: 0.1897\n",
      "Epoch 26/105\n",
      "6136/6136 [==============================] - 34s 5ms/step - loss: 0.9651 - decoded_loss: 0.1505 - target_loss: 0.8146 - target_PearsonCorrelation: 0.1897\n",
      "Epoch 27/105\n",
      "6136/6136 [==============================] - 36s 6ms/step - loss: 0.9649 - decoded_loss: 0.1504 - target_loss: 0.8145 - target_PearsonCorrelation: 0.1900\n",
      "Epoch 28/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9651 - decoded_loss: 0.1502 - target_loss: 0.8148 - target_PearsonCorrelation: 0.1890\n",
      "Epoch 29/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9650 - decoded_loss: 0.1504 - target_loss: 0.8146 - target_PearsonCorrelation: 0.1897\n",
      "Epoch 30/105\n",
      "6136/6136 [==============================] - 37s 6ms/step - loss: 0.9649 - decoded_loss: 0.1503 - target_loss: 0.8146 - target_PearsonCorrelation: 0.1896\n",
      "Epoch 31/105\n",
      "6136/6136 [==============================] - 34s 5ms/step - loss: 0.9650 - decoded_loss: 0.1504 - target_loss: 0.8145 - target_PearsonCorrelation: 0.1899\n",
      "Epoch 32/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9650 - decoded_loss: 0.1506 - target_loss: 0.8145 - target_PearsonCorrelation: 0.1900\n",
      "Epoch 33/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9652 - decoded_loss: 0.1507 - target_loss: 0.8145 - target_PearsonCorrelation: 0.1903\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0003024999983608723.\n",
      "Epoch 34/105\n",
      "6136/6136 [==============================] - 37s 6ms/step - loss: 0.9629 - decoded_loss: 0.1450 - target_loss: 0.8179 - target_PearsonCorrelation: 0.1800\n",
      "Epoch 35/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9613 - decoded_loss: 0.1439 - target_loss: 0.8174 - target_PearsonCorrelation: 0.1815\n",
      "Epoch 36/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9607 - decoded_loss: 0.1435 - target_loss: 0.8172 - target_PearsonCorrelation: 0.1819\n",
      "Epoch 37/105\n",
      "6136/6136 [==============================] - 38s 6ms/step - loss: 0.9601 - decoded_loss: 0.1432 - target_loss: 0.8170 - target_PearsonCorrelation: 0.1828\n",
      "Epoch 38/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9599 - decoded_loss: 0.1429 - target_loss: 0.8171 - target_PearsonCorrelation: 0.1824\n",
      "Epoch 39/105\n",
      "6136/6136 [==============================] - 34s 5ms/step - loss: 0.9596 - decoded_loss: 0.1426 - target_loss: 0.8170 - target_PearsonCorrelation: 0.1826\n",
      "Epoch 40/105\n",
      "6136/6136 [==============================] - 35s 6ms/step - loss: 0.9595 - decoded_loss: 0.1426 - target_loss: 0.8169 - target_PearsonCorrelation: 0.1831\n",
      "Epoch 41/105\n",
      "6136/6136 [==============================] - 38s 6ms/step - loss: 0.9592 - decoded_loss: 0.1425 - target_loss: 0.8167 - target_PearsonCorrelation: 0.1838\n",
      "Epoch 42/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9592 - decoded_loss: 0.1425 - target_loss: 0.8167 - target_PearsonCorrelation: 0.1836\n",
      "Epoch 43/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9591 - decoded_loss: 0.1425 - target_loss: 0.8166 - target_PearsonCorrelation: 0.1838\n",
      "Epoch 44/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9591 - decoded_loss: 0.1425 - target_loss: 0.8166 - target_PearsonCorrelation: 0.1838\n",
      "Epoch 45/105\n",
      "6136/6136 [==============================] - 39s 6ms/step - loss: 0.9593 - decoded_loss: 0.1425 - target_loss: 0.8168 - target_PearsonCorrelation: 0.1831\n",
      "Epoch 46/105\n",
      "6136/6136 [==============================] - 35s 6ms/step - loss: 0.9590 - decoded_loss: 0.1424 - target_loss: 0.8166 - target_PearsonCorrelation: 0.1837\n",
      "Epoch 47/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9588 - decoded_loss: 0.1423 - target_loss: 0.8165 - target_PearsonCorrelation: 0.1841\n",
      "Epoch 48/105\n",
      "6136/6136 [==============================] - 36s 6ms/step - loss: 0.9590 - decoded_loss: 0.1425 - target_loss: 0.8165 - target_PearsonCorrelation: 0.1844\n",
      "Epoch 49/105\n",
      "6136/6136 [==============================] - 36s 6ms/step - loss: 0.9589 - decoded_loss: 0.1426 - target_loss: 0.8163 - target_PearsonCorrelation: 0.1849\n",
      "Epoch 50/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9589 - decoded_loss: 0.1425 - target_loss: 0.8164 - target_PearsonCorrelation: 0.1845\n",
      "Epoch 51/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9589 - decoded_loss: 0.1424 - target_loss: 0.8165 - target_PearsonCorrelation: 0.1841\n",
      "Epoch 52/105\n",
      "6136/6136 [==============================] - 39s 6ms/step - loss: 0.9589 - decoded_loss: 0.1425 - target_loss: 0.8164 - target_PearsonCorrelation: 0.1845\n",
      "Epoch 53/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9589 - decoded_loss: 0.1426 - target_loss: 0.8163 - target_PearsonCorrelation: 0.1848\n",
      "Epoch 54/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9589 - decoded_loss: 0.1426 - target_loss: 0.8163 - target_PearsonCorrelation: 0.1847\n",
      "Epoch 55/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9589 - decoded_loss: 0.1425 - target_loss: 0.8164 - target_PearsonCorrelation: 0.1846\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00016637500229990112.\n",
      "Epoch 56/105\n",
      "6136/6136 [==============================] - 41s 7ms/step - loss: 0.9575 - decoded_loss: 0.1384 - target_loss: 0.8191 - target_PearsonCorrelation: 0.1760\n",
      "Epoch 57/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9566 - decoded_loss: 0.1378 - target_loss: 0.8188 - target_PearsonCorrelation: 0.1772\n",
      "Epoch 58/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9561 - decoded_loss: 0.1373 - target_loss: 0.8188 - target_PearsonCorrelation: 0.1772\n",
      "Epoch 59/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9558 - decoded_loss: 0.1371 - target_loss: 0.8187 - target_PearsonCorrelation: 0.1773\n",
      "Epoch 60/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9553 - decoded_loss: 0.1369 - target_loss: 0.8185 - target_PearsonCorrelation: 0.1781\n",
      "Epoch 61/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9553 - decoded_loss: 0.1367 - target_loss: 0.8185 - target_PearsonCorrelation: 0.1778\n",
      "Epoch 62/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9551 - decoded_loss: 0.1366 - target_loss: 0.8184 - target_PearsonCorrelation: 0.1780\n",
      "Epoch 63/105\n",
      "6136/6136 [==============================] - 41s 7ms/step - loss: 0.9550 - decoded_loss: 0.1366 - target_loss: 0.8183 - target_PearsonCorrelation: 0.1785\n",
      "Epoch 64/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9548 - decoded_loss: 0.1365 - target_loss: 0.8183 - target_PearsonCorrelation: 0.1786\n",
      "Epoch 65/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9546 - decoded_loss: 0.1365 - target_loss: 0.8181 - target_PearsonCorrelation: 0.1794\n",
      "Epoch 66/105\n",
      "6136/6136 [==============================] - 35s 6ms/step - loss: 0.9544 - decoded_loss: 0.1364 - target_loss: 0.8180 - target_PearsonCorrelation: 0.1795\n",
      "Epoch 67/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9543 - decoded_loss: 0.1364 - target_loss: 0.8179 - target_PearsonCorrelation: 0.1797\n",
      "Epoch 68/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9545 - decoded_loss: 0.1363 - target_loss: 0.8182 - target_PearsonCorrelation: 0.1790\n",
      "Epoch 69/105\n",
      "6136/6136 [==============================] - 40s 6ms/step - loss: 0.9541 - decoded_loss: 0.1362 - target_loss: 0.8179 - target_PearsonCorrelation: 0.1798\n",
      "Epoch 70/105\n",
      "6136/6136 [==============================] - 35s 6ms/step - loss: 0.9540 - decoded_loss: 0.1362 - target_loss: 0.8178 - target_PearsonCorrelation: 0.1803\n",
      "Epoch 71/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9541 - decoded_loss: 0.1362 - target_loss: 0.8179 - target_PearsonCorrelation: 0.1798\n",
      "Epoch 72/105\n",
      "6136/6136 [==============================] - 34s 5ms/step - loss: 0.9539 - decoded_loss: 0.1361 - target_loss: 0.8178 - target_PearsonCorrelation: 0.1800\n",
      "Epoch 73/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9537 - decoded_loss: 0.1359 - target_loss: 0.8177 - target_PearsonCorrelation: 0.1803\n",
      "Epoch 74/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9539 - decoded_loss: 0.1359 - target_loss: 0.8180 - target_PearsonCorrelation: 0.1794\n",
      "Epoch 75/105\n",
      "6136/6136 [==============================] - 42s 7ms/step - loss: 0.9538 - decoded_loss: 0.1358 - target_loss: 0.8179 - target_PearsonCorrelation: 0.1798\n",
      "Epoch 76/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9537 - decoded_loss: 0.1358 - target_loss: 0.8180 - target_PearsonCorrelation: 0.1795\n",
      "Epoch 77/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9538 - decoded_loss: 0.1358 - target_loss: 0.8180 - target_PearsonCorrelation: 0.1794\n",
      "Epoch 78/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9536 - decoded_loss: 0.1358 - target_loss: 0.8178 - target_PearsonCorrelation: 0.1802\n",
      "Epoch 79/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9534 - decoded_loss: 0.1356 - target_loss: 0.8177 - target_PearsonCorrelation: 0.1805\n",
      "Epoch 80/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9532 - decoded_loss: 0.1356 - target_loss: 0.8176 - target_PearsonCorrelation: 0.1808\n",
      "Epoch 81/105\n",
      "6136/6136 [==============================] - 39s 6ms/step - loss: 0.9534 - decoded_loss: 0.1356 - target_loss: 0.8177 - target_PearsonCorrelation: 0.1804\n",
      "Epoch 82/105\n",
      "6136/6136 [==============================] - 38s 6ms/step - loss: 0.9536 - decoded_loss: 0.1356 - target_loss: 0.8179 - target_PearsonCorrelation: 0.1798\n",
      "Epoch 83/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9532 - decoded_loss: 0.1356 - target_loss: 0.8176 - target_PearsonCorrelation: 0.1808\n",
      "Epoch 84/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9533 - decoded_loss: 0.1356 - target_loss: 0.8177 - target_PearsonCorrelation: 0.1803\n",
      "Epoch 85/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9532 - decoded_loss: 0.1356 - target_loss: 0.8175 - target_PearsonCorrelation: 0.1809\n",
      "Epoch 86/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9530 - decoded_loss: 0.1356 - target_loss: 0.8175 - target_PearsonCorrelation: 0.1810\n",
      "Epoch 87/105\n",
      "6136/6136 [==============================] - 34s 5ms/step - loss: 0.9531 - decoded_loss: 0.1356 - target_loss: 0.8175 - target_PearsonCorrelation: 0.1812\n",
      "Epoch 88/105\n",
      "6136/6136 [==============================] - 38s 6ms/step - loss: 0.9531 - decoded_loss: 0.1357 - target_loss: 0.8174 - target_PearsonCorrelation: 0.1814\n",
      "Epoch 89/105\n",
      "6136/6136 [==============================] - 40s 6ms/step - loss: 0.9530 - decoded_loss: 0.1357 - target_loss: 0.8173 - target_PearsonCorrelation: 0.1816\n",
      "Epoch 90/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9530 - decoded_loss: 0.1357 - target_loss: 0.8173 - target_PearsonCorrelation: 0.1817\n",
      "Epoch 91/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9532 - decoded_loss: 0.1357 - target_loss: 0.8176 - target_PearsonCorrelation: 0.1807\n",
      "Epoch 92/105\n",
      "6136/6136 [==============================] - 33s 5ms/step - loss: 0.9529 - decoded_loss: 0.1357 - target_loss: 0.8173 - target_PearsonCorrelation: 0.1818\n",
      "Epoch 93/105\n",
      "6136/6136 [==============================] - 34s 5ms/step - loss: 0.9528 - decoded_loss: 0.1356 - target_loss: 0.8172 - target_PearsonCorrelation: 0.1822\n",
      "Epoch 94/105\n",
      "6136/6136 [==============================] - 34s 6ms/step - loss: 0.9530 - decoded_loss: 0.1357 - target_loss: 0.8173 - target_PearsonCorrelation: 0.1819\n",
      "训练mlp**********************************************************************************************\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          153600      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mish_2 (Mish)                   (None, 512)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           mish_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          65664       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mish_3 (Mish)                   (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 256)          78256       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 384)          0           mish_3[0][0]                     \n",
      "                                                                 model[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 384)          1536        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          196608      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 512)          2048        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mish_4 (Mish)                   (None, 512)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           mish_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          131072      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256)          1024        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mish_5 (Mish)                   (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           mish_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          65536       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mish_6 (Mish)                   (None, 256)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           mish_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          32768       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128)          512         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mish_7 (Mish)                   (None, 128)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           mish_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            129         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 731,825\n",
      "Trainable params: 649,473\n",
      "Non-trainable params: 82,352\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/12\n",
      "6136/6136 [==============================] - 53s 8ms/step - loss: 0.8399 - PearsonCorrelation: 0.1341\n",
      "Epoch 2/12\n",
      "6136/6136 [==============================] - 46s 7ms/step - loss: 0.8262 - PearsonCorrelation: 0.1511\n",
      "Epoch 3/12\n",
      "6136/6136 [==============================] - 46s 7ms/step - loss: 0.8252 - PearsonCorrelation: 0.1551\n",
      "Epoch 4/12\n",
      "6136/6136 [==============================] - 46s 7ms/step - loss: 0.8244 - PearsonCorrelation: 0.1580\n",
      "Epoch 5/12\n",
      "6136/6136 [==============================] - 47s 8ms/step - loss: 0.8226 - PearsonCorrelation: 0.1646\n",
      "Epoch 6/12\n",
      "6136/6136 [==============================] - 56s 9ms/step - loss: 0.8211 - PearsonCorrelation: 0.1704\n",
      "Epoch 7/12\n",
      "6136/6136 [==============================] - 46s 8ms/step - loss: 0.8198 - PearsonCorrelation: 0.1748\n",
      "Epoch 8/12\n",
      "6136/6136 [==============================] - 46s 7ms/step - loss: 0.8186 - PearsonCorrelation: 0.1787\n",
      "Epoch 9/12\n",
      "6136/6136 [==============================] - 46s 8ms/step - loss: 0.8171 - PearsonCorrelation: 0.1832\n",
      "Epoch 10/12\n",
      "6136/6136 [==============================] - 56s 9ms/step - loss: 0.8159 - PearsonCorrelation: 0.1874\n",
      "Epoch 11/12\n",
      "6136/6136 [==============================] - 46s 8ms/step - loss: 0.8139 - PearsonCorrelation: 0.1934\n",
      "Epoch 12/12\n",
      "6136/6136 [==============================] - 46s 7ms/step - loss: 0.8125 - PearsonCorrelation: 0.1977\n",
      "\n",
      " Ave_Person_Score: 0.15744116467380348\n",
      " Positive_Person_Score: 0.1684999729263989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if cfg.full_train:\n",
    "    if cfg.freeze_enco:\n",
    "        encoder = get_encoder(mode='freeze')\n",
    "    else:\n",
    "        callback = [callbacks.ReduceLROnPlateau(monitor='loss', patience=8, factor=0.55, verbose=1),\n",
    "                    callbacks.EarlyStopping(monitor='loss', patience=16, restore_best_weights=True, min_delta=0.0012)]\n",
    "        train_ds = make_dataset(fea_data, target[:, 1], batch_size=cfg.enco_batch_size, to='encoder')\n",
    "        encoder = get_encoder(mode='new', train_ds=train_ds, the_callback=callback)\n",
    "        del train_ds\n",
    "        gc.collect()\n",
    "        \n",
    "    callback = [callbacks.ReduceLROnPlateau(monitor='loss', verbose=1, \n",
    "                                            patience=cfg.cb_rlrp_patience, \n",
    "                                            factor=cfg.cb_rlrp_factor),\n",
    "                callbacks.ModelCheckpoint(cfg.fulltr_savedir,\n",
    "                                          monitor='loss', save_freq='epoch',\n",
    "                                          save_best_only=False,\n",
    "                                          save_weights_only=True)]\n",
    "    print('训练mlp**********************************************************************************************')\n",
    "    the_model = build_model(encoder)\n",
    "    see_model_config(the_model)\n",
    "    train_ds = make_dataset(fea_data, target[:, 1], batch_size=cfg.mlp_batch_size)\n",
    "    the_model.fit(train_ds,\n",
    "                  epochs=cfg.mlp_epoch,\n",
    "                  callbacks=callback,\n",
    "                  verbose=1)\n",
    "    \n",
    "    ave_person_score, pos_ave_person_score = metrics_ave_time_id(target, the_model.predict(fea_data, batch_size=2048))\n",
    "    print('\\n Ave_Person_Score: {0}\\n Positive_Person_Score: {1}\\n'.format(ave_person_score, pos_ave_person_score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "909a7f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T03:55:45.440628Z",
     "iopub.status.busy": "2022-04-14T03:55:45.439628Z",
     "iopub.status.idle": "2022-04-14T03:55:45.441580Z",
     "shell.execute_reply": "2022-04-14T03:55:45.442121Z",
     "shell.execute_reply.started": "2022-03-28T02:53:25.340404Z"
    },
    "papermill": {
     "duration": 20.215291,
     "end_time": "2022-04-14T03:55:45.442293",
     "exception": false,
     "start_time": "2022-04-14T03:55:25.227002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not cfg.full_train:\n",
    "    if cfg.just_train_enco:\n",
    "        train_ds = make_dataset(fea_data, target[:, 1], batch_size=cfg.enco_batch_size, to='encoder')\n",
    "        callback = [callbacks.ReduceLROnPlateau(monitor='loss', patience=8, factor=0.55, verbose=1),\n",
    "                    callbacks.EarlyStopping(monitor='loss', patience=18, restore_best_weights=True, min_delta=0.001)]\n",
    "        get_encoder(mode='new', train_ds=train_ds, the_callback=callback)\n",
    "\n",
    "    else:\n",
    "        if cfg.freeze_enco:\n",
    "            encoder = get_encoder(mode='freeze')\n",
    "            \n",
    "        if cfg.use_time_kfold:\n",
    "            kfold = TimeSeriesSplit(n_splits=cfg.split_n)\n",
    "        else:\n",
    "            kfold = KFold(n_splits=cfg.split_n, shuffle=True, random_state=cfg.simple_kfold_seed)\n",
    "\n",
    "        for fold, (train_ind, test_ind) in enumerate(kfold.split(fea_data, target)):\n",
    "\n",
    "            if cfg.use_time_kfold:\n",
    "                if fold < cfg.t_kfold_start:\n",
    "                    continue\n",
    "\n",
    "            print('训练集大小：{0:}'.format(len(train_ind)))\n",
    "            print('测试集大小：{0:}'.format(len(test_ind)))\n",
    "            train_ox = fea_data[train_ind]\n",
    "            test_ox = fea_data[test_ind]\n",
    "            train_target = target[train_ind]\n",
    "            test_target = target[test_ind]\n",
    "            \n",
    "             \n",
    "            callback = [callbacks.ReduceLROnPlateau(monitor=cfg.cb_monitor,\n",
    "                                                    patience=cfg.cb_rlrp_patience,\n",
    "                                                    factor=cfg.cb_rlrp_factor, verbose=1),\n",
    "                        callbacks.EarlyStopping(monitor=cfg.cb_monitor,\n",
    "                                                patience=cfg.cb_es_patience,\n",
    "                                                restore_best_weights=True)]   \n",
    "\n",
    "            if not cfg.freeze_enco:\n",
    "                train_ds = make_dataset(train_ox, train_target[:, 1], batch_size=cfg.enco_batch_size, to='encoder')\n",
    "                test_ds = make_dataset(test_ox, test_target[:, 1], batch_size=cfg.test_batch_size, mode='valid', to='encoder')\n",
    "                print('训练encoder')\n",
    "                encoder = get_encoder(mode='cv', train_ds=train_ds, test_ds=test_ds, the_callback=callback)\n",
    "                del train_ds, test_ds\n",
    "                gc.collect()\n",
    "                print('\\n\\n')\n",
    "            \n",
    "            the_model = build_model(encoder)\n",
    "\n",
    "            if cfg.use_time_kfold:\n",
    "                if fold == cfg.t_kfold_start:\n",
    "                    see_model_config(the_model)\n",
    "            if not fold:\n",
    "                see_model_config(the_model)\n",
    "\n",
    "            train_ds = make_dataset(train_ox, train_target[:, 1], batch_size=cfg.mlp_batch_size)\n",
    "            test_ds = make_dataset(test_ox, test_target[:, 1], batch_size=cfg.test_batch_size, mode='valid')\n",
    "            the_model.fit(train_ds,\n",
    "                          epochs=cfg.mlp_epoch,\n",
    "                          callbacks=callback,\n",
    "                          validation_data=test_ds,\n",
    "                          verbose=2)\n",
    "            del train_ds, test_ds\n",
    "            gc.collect()\n",
    "            the_model.save_weights(cfg.save_mlp_dir(fold))\n",
    "\n",
    "            ave_person_score, pos_ave_person_score = metrics_ave_time_id(test_target, the_model.predict(test_ox, batch_size=2048))\n",
    "            print('\\n Ave_Person_Score: {0}\\n Positive_Person_Score: {1}\\n'.format(ave_person_score, pos_ave_person_score))\n",
    "            print('**************************************************************************************************\\n')\n",
    "            K.clear_session()\n",
    "            if not cfg.use_time_kfold:\n",
    "                if fold == cfg.simple_kfold_get:\n",
    "                    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4692.594636,
   "end_time": "2022-04-14T03:56:08.690311",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-14T02:37:56.095675",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
