{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b294a8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-19T12:00:30.490757Z",
     "iopub.status.busy": "2022-04-19T12:00:30.489268Z",
     "iopub.status.idle": "2022-04-19T12:00:30.499315Z",
     "shell.execute_reply": "2022-04-19T12:00:30.498791Z",
     "shell.execute_reply.started": "2022-04-18T16:30:33.921337Z"
    },
    "papermill": {
     "duration": 0.034384,
     "end_time": "2022-04-19T12:00:30.499450",
     "exception": false,
     "start_time": "2022-04-19T12:00:30.465066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab737ad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T12:00:30.546074Z",
     "iopub.status.busy": "2022-04-19T12:00:30.545305Z",
     "iopub.status.idle": "2022-04-19T12:00:30.547658Z",
     "shell.execute_reply": "2022-04-19T12:00:30.547231Z",
     "shell.execute_reply.started": "2022-04-18T16:30:34.118753Z"
    },
    "papermill": {
     "duration": 0.029082,
     "end_time": "2022-04-19T12:00:30.547757",
     "exception": false,
     "start_time": "2022-04-19T12:00:30.518675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    fea_dir = '../input/ubiquant-train-data/ori_train_data_feature_f16.npy'\n",
    "    target_dir = '../input/ubiquant-train-data/train_(timeid)target-f32.npy'\n",
    "    tfrecords_dir = '../input/ubiquant-train-data/train_data_target-f32-all.tfrecords'\n",
    "    time_dir = None\n",
    "    inv_dir = None\n",
    "\n",
    "    input_dim = 300\n",
    "    enco_noise_rate = 0.05\n",
    "\n",
    "    full_train = True\n",
    "\n",
    "    just_train_enco = False\n",
    "    freeze_enco = False\n",
    "    enco_weights_dir = '../input/encoderonly-feaall-data/cur-best-encoder.h5'\n",
    "\n",
    "    mlp_batch_size = 1024\n",
    "    enco_batch_size = 1024\n",
    "    test_batch_size = 4096\n",
    "    train_shuffle_seed = 113\n",
    "\n",
    "    split_n = 6\n",
    "    use_time_kfold = True\n",
    "    t_kfold_start = 4\n",
    "    simple_kfold_get = 2\n",
    "    simple_kfold_seed = 125\n",
    "\n",
    "    mlp_LR = 0.001\n",
    "    enco_LR = 0.001\n",
    "\n",
    "    cb_monitor = 'val_loss'\n",
    "    cb_rlrp_patience = 8\n",
    "    cb_rlrp_factor = 0.6\n",
    "    cb_es_patience = 15\n",
    "\n",
    "    mlp_epoch = 9\n",
    "    enco_epoch = 120\n",
    "\n",
    "    #     fulltr_savedir = './fulltr-origin-ep{epoch}.h5'\n",
    "\n",
    "    def fulltr_savedir(self, i):\n",
    "        return './fulltr-origin-ep{epoch}.h5'\n",
    "\n",
    "    def save_mlp_dir(self, the_fold):\n",
    "        return './origin-bigdrop-test-1_{0}.h5'.format(the_fold)\n",
    "\n",
    "    def save_encoder_dir(self):\n",
    "        return './fulltr-enco256256-{0}.h5'.format('full-train-unfreeze-1')\n",
    "\n",
    "\n",
    "cfg = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45ccab5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T12:00:30.590824Z",
     "iopub.status.busy": "2022-04-19T12:00:30.590259Z",
     "iopub.status.idle": "2022-04-19T12:00:36.049838Z",
     "shell.execute_reply": "2022-04-19T12:00:36.049203Z",
     "shell.execute_reply.started": "2022-04-18T16:30:34.299582Z"
    },
    "papermill": {
     "duration": 5.483446,
     "end_time": "2022-04-19T12:00:36.050005",
     "exception": false,
     "start_time": "2022-04-19T12:00:30.566559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b8dc3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T12:00:36.293615Z",
     "iopub.status.busy": "2022-04-19T12:00:36.292699Z",
     "iopub.status.idle": "2022-04-19T12:00:36.296786Z",
     "shell.execute_reply": "2022-04-19T12:00:36.297375Z",
     "shell.execute_reply.started": "2022-04-18T16:30:40.111092Z"
    },
    "papermill": {
     "duration": 0.224805,
     "end_time": "2022-04-19T12:00:36.297524",
     "exception": false,
     "start_time": "2022-04-19T12:00:36.072719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 12:00:36.157377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 12:00:36.288625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 12:00:36.289553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices(device_type='GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5317d14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T12:00:36.351530Z",
     "iopub.status.busy": "2022-04-19T12:00:36.349309Z",
     "iopub.status.idle": "2022-04-19T12:00:36.354006Z",
     "shell.execute_reply": "2022-04-19T12:00:36.353480Z",
     "shell.execute_reply.started": "2022-04-18T16:30:40.280737Z"
    },
    "papermill": {
     "duration": 0.034357,
     "end_time": "2022-04-19T12:00:36.354140",
     "exception": false,
     "start_time": "2022-04-19T12:00:36.319783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mish(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Mish, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        return inputs * K.tanh(K.softplus(inputs))\n",
    "    \n",
    "def PearsonCorrelation(y_true, y_pred):\n",
    "    yt_mean = K.mean(y_true)\n",
    "    yp_mean = K.mean(y_pred)\n",
    "    cor = K.mean((y_true - yt_mean) * (y_pred - yp_mean))\n",
    "    yt_std = K.std(y_true)\n",
    "    yp_std = K.std(y_pred)\n",
    "    pearson = cor / (yt_std * yp_std)\n",
    "    return pearson\n",
    "\n",
    "def PearsonCorrelationLoss(y_true, y_pred):\n",
    "    return K.constant(1.0, dtype=y_pred.dtype) - PearsonCorrelation(y_true, y_pred)\n",
    "\n",
    "def MyLoss(y_true, y_pred):\n",
    "    return losses.mean_squared_error(y_true, y_pred) * 0.5 + PearsonCorrelationLoss(y_true, y_pred) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fdb085f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T12:00:36.406010Z",
     "iopub.status.busy": "2022-04-19T12:00:36.405407Z",
     "iopub.status.idle": "2022-04-19T12:03:03.879009Z",
     "shell.execute_reply": "2022-04-19T12:03:03.878505Z",
     "shell.execute_reply.started": "2022-04-18T16:30:40.298503Z"
    },
    "papermill": {
     "duration": 147.503672,
     "end_time": "2022-04-19T12:03:03.879163",
     "exception": false,
     "start_time": "2022-04-19T12:00:36.375491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3141410, 300) float16\n",
      "(3141410,) float32\n",
      "0.48264834\n",
      "(4084371,) float32\n",
      "(942961, 300)\n",
      "(4084371, 300) float16\n"
     ]
    }
   ],
   "source": [
    "new_model = []\n",
    "\n",
    "fea_data = np.load(cfg.fea_dir)\n",
    "target = np.load(cfg.target_dir)[:, 1]\n",
    "print(fea_data.shape, fea_data.dtype)\n",
    "print(target.shape, target.dtype)\n",
    "\n",
    "path = '../input/ubiquant-market-prediction/supplemental_train.csv'\n",
    "dtypes = {\n",
    "    'row_id': 'str',\n",
    "    'time_id': 'uint16',\n",
    "    'investment_id': 'uint16',\n",
    "    'target': 'float32',\n",
    "}\n",
    "\n",
    "for i in range(300):\n",
    "    dtypes[f'f_{i}'] = 'float16'\n",
    "sup_train = pd.read_csv(path,usecols=list(dtypes.keys()),dtype=dtypes)\n",
    "sup_target = sup_train['target'].values\n",
    "print(sup_target[0])\n",
    "target = np.concatenate((target, sup_target))\n",
    "print(target.shape, target.dtype)\n",
    "sup_train = sup_train.drop(columns=['row_id', 'time_id', 'investment_id', 'target']).values\n",
    "print(sup_train.shape)\n",
    "fea_data = np.row_stack((fea_data, sup_train))\n",
    "print(fea_data.shape, fea_data.dtype)\n",
    "del sup_train, sup_target\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "763ea43f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T12:03:03.925752Z",
     "iopub.status.busy": "2022-04-19T12:03:03.924825Z",
     "iopub.status.idle": "2022-04-19T12:04:43.082086Z",
     "shell.execute_reply": "2022-04-19T12:04:43.081616Z",
     "shell.execute_reply.started": "2022-04-18T16:33:04.274793Z"
    },
    "papermill": {
     "duration": 99.182081,
     "end_time": "2022-04-19T12:04:43.082247",
     "exception": false,
     "start_time": "2022-04-19T12:03:03.900166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler_0 = StandardScaler()\n",
    "fea_data = scaler_0.fit_transform(fea_data)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322a46d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T12:04:43.146513Z",
     "iopub.status.busy": "2022-04-19T12:04:43.136935Z",
     "iopub.status.idle": "2022-04-19T13:56:46.420791Z",
     "shell.execute_reply": "2022-04-19T13:56:46.420106Z",
     "shell.execute_reply.started": "2022-04-18T16:34:44.257784Z"
    },
    "papermill": {
     "duration": 6723.318844,
     "end_time": "2022-04-19T13:56:46.421820",
     "exception": false,
     "start_time": "2022-04-19T12:04:43.102976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 12:04:43.157056: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-19 12:04:43.157775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 12:04:43.158653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 12:04:43.159298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 12:04:44.909208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 12:04:44.910048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 12:04:44.910765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-19 12:04:44.912292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-04-19 12:04:47.820734: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2450622600 exceeds 10% of free system memory.\n",
      "2022-04-19 12:04:54.241545: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2450622600 exceeds 10% of free system memory.\n",
      "2022-04-19 12:04:56.846468: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2450622600 exceeds 10% of free system memory.\n",
      "2022-04-19 12:04:58.718975: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2450622600 exceeds 10% of free system memory.\n",
      "2022-04-19 12:05:01.144601: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2450622600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-19 12:05:08.981930: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3989/3989 - 32s - loss: 0.9815 - decoded_loss: 0.3017 - target_out_loss: 0.6798\n",
      "Epoch 2/120\n",
      "3989/3989 - 29s - loss: 0.8264 - decoded_loss: 0.1715 - target_out_loss: 0.6549\n",
      "Epoch 3/120\n",
      "3989/3989 - 29s - loss: 0.8130 - decoded_loss: 0.1589 - target_out_loss: 0.6541\n",
      "Epoch 4/120\n",
      "3989/3989 - 29s - loss: 0.8074 - decoded_loss: 0.1540 - target_out_loss: 0.6534\n",
      "Epoch 5/120\n",
      "3989/3989 - 29s - loss: 0.8043 - decoded_loss: 0.1516 - target_out_loss: 0.6527\n",
      "Epoch 6/120\n",
      "3989/3989 - 29s - loss: 0.8025 - decoded_loss: 0.1499 - target_out_loss: 0.6527\n",
      "Epoch 7/120\n",
      "3989/3989 - 29s - loss: 0.8014 - decoded_loss: 0.1487 - target_out_loss: 0.6527\n",
      "Epoch 8/120\n",
      "3989/3989 - 29s - loss: 0.8004 - decoded_loss: 0.1479 - target_out_loss: 0.6525\n",
      "Epoch 9/120\n",
      "3989/3989 - 29s - loss: 0.7998 - decoded_loss: 0.1474 - target_out_loss: 0.6523\n",
      "Epoch 10/120\n",
      "3989/3989 - 30s - loss: 0.7993 - decoded_loss: 0.1470 - target_out_loss: 0.6523\n",
      "Epoch 11/120\n",
      "3989/3989 - 29s - loss: 0.7990 - decoded_loss: 0.1467 - target_out_loss: 0.6523\n",
      "Epoch 12/120\n",
      "3989/3989 - 29s - loss: 0.7992 - decoded_loss: 0.1468 - target_out_loss: 0.6524\n",
      "Epoch 13/120\n",
      "3989/3989 - 29s - loss: 0.7987 - decoded_loss: 0.1465 - target_out_loss: 0.6522\n",
      "Epoch 14/120\n",
      "3989/3989 - 29s - loss: 0.7986 - decoded_loss: 0.1464 - target_out_loss: 0.6521\n",
      "Epoch 15/120\n",
      "3989/3989 - 30s - loss: 0.7987 - decoded_loss: 0.1464 - target_out_loss: 0.6523\n",
      "Epoch 16/120\n",
      "3989/3989 - 30s - loss: 0.7986 - decoded_loss: 0.1465 - target_out_loss: 0.6521\n",
      "Epoch 17/120\n",
      "3989/3989 - 29s - loss: 0.7985 - decoded_loss: 0.1463 - target_out_loss: 0.6521\n",
      "Epoch 18/120\n",
      "3989/3989 - 29s - loss: 0.7984 - decoded_loss: 0.1463 - target_out_loss: 0.6521\n",
      "Epoch 19/120\n",
      "3989/3989 - 30s - loss: 0.7985 - decoded_loss: 0.1464 - target_out_loss: 0.6522\n",
      "Epoch 20/120\n",
      "3989/3989 - 29s - loss: 0.7987 - decoded_loss: 0.1464 - target_out_loss: 0.6522\n",
      "Epoch 21/120\n",
      "3989/3989 - 30s - loss: 0.7986 - decoded_loss: 0.1464 - target_out_loss: 0.6522\n",
      "Epoch 22/120\n",
      "3989/3989 - 30s - loss: 0.7986 - decoded_loss: 0.1465 - target_out_loss: 0.6521\n",
      "Epoch 23/120\n",
      "3989/3989 - 29s - loss: 0.7985 - decoded_loss: 0.1466 - target_out_loss: 0.6520\n",
      "Epoch 24/120\n",
      "3989/3989 - 29s - loss: 0.7987 - decoded_loss: 0.1468 - target_out_loss: 0.6520\n",
      "Epoch 25/120\n",
      "3989/3989 - 29s - loss: 0.7986 - decoded_loss: 0.1466 - target_out_loss: 0.6520\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 26/120\n",
      "3989/3989 - 29s - loss: 0.7984 - decoded_loss: 0.1445 - target_out_loss: 0.6539\n",
      "Epoch 27/120\n",
      "3989/3989 - 29s - loss: 0.7971 - decoded_loss: 0.1434 - target_out_loss: 0.6538\n",
      "Epoch 28/120\n",
      "3989/3989 - 29s - loss: 0.7966 - decoded_loss: 0.1428 - target_out_loss: 0.6538\n",
      "Epoch 29/120\n",
      "3989/3989 - 29s - loss: 0.7962 - decoded_loss: 0.1425 - target_out_loss: 0.6537\n",
      "Epoch 30/120\n",
      "3989/3989 - 29s - loss: 0.7962 - decoded_loss: 0.1425 - target_out_loss: 0.6538\n",
      "Epoch 31/120\n",
      "3989/3989 - 29s - loss: 0.7961 - decoded_loss: 0.1424 - target_out_loss: 0.6537\n",
      "Epoch 32/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1423 - target_out_loss: 0.6535\n",
      "Epoch 33/120\n",
      "3989/3989 - 29s - loss: 0.7959 - decoded_loss: 0.1425 - target_out_loss: 0.6535\n",
      "Epoch 34/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1423 - target_out_loss: 0.6535\n",
      "Epoch 35/120\n",
      "3989/3989 - 29s - loss: 0.7959 - decoded_loss: 0.1423 - target_out_loss: 0.6536\n",
      "Epoch 36/120\n",
      "3989/3989 - 30s - loss: 0.7957 - decoded_loss: 0.1422 - target_out_loss: 0.6535\n",
      "Epoch 37/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1425 - target_out_loss: 0.6534\n",
      "Epoch 38/120\n",
      "3989/3989 - 30s - loss: 0.7959 - decoded_loss: 0.1425 - target_out_loss: 0.6534\n",
      "Epoch 39/120\n",
      "3989/3989 - 29s - loss: 0.7957 - decoded_loss: 0.1423 - target_out_loss: 0.6534\n",
      "Epoch 40/120\n",
      "3989/3989 - 29s - loss: 0.7959 - decoded_loss: 0.1425 - target_out_loss: 0.6534\n",
      "Epoch 41/120\n",
      "3989/3989 - 30s - loss: 0.7957 - decoded_loss: 0.1423 - target_out_loss: 0.6534\n",
      "Epoch 42/120\n",
      "3989/3989 - 30s - loss: 0.7956 - decoded_loss: 0.1423 - target_out_loss: 0.6533\n",
      "Epoch 43/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1424 - target_out_loss: 0.6533\n",
      "Epoch 44/120\n",
      "3989/3989 - 30s - loss: 0.7958 - decoded_loss: 0.1425 - target_out_loss: 0.6533\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 45/120\n",
      "3989/3989 - 30s - loss: 0.7988 - decoded_loss: 0.1434 - target_out_loss: 0.6554\n",
      "Epoch 46/120\n",
      "3989/3989 - 29s - loss: 0.7973 - decoded_loss: 0.1422 - target_out_loss: 0.6551\n",
      "Epoch 47/120\n",
      "3989/3989 - 29s - loss: 0.7966 - decoded_loss: 0.1414 - target_out_loss: 0.6551\n",
      "Epoch 1/9\n",
      "3989/3989 - 33s - loss: 0.6719\n",
      "Epoch 2/9\n",
      "3989/3989 - 32s - loss: 0.6593\n",
      "Epoch 3/9\n",
      "3989/3989 - 32s - loss: 0.6580\n",
      "Epoch 4/9\n",
      "3989/3989 - 32s - loss: 0.6574\n",
      "Epoch 5/9\n",
      "3989/3989 - 31s - loss: 0.6564\n",
      "Epoch 6/9\n",
      "3989/3989 - 32s - loss: 0.6555\n",
      "Epoch 7/9\n",
      "3989/3989 - 32s - loss: 0.6545\n",
      "Epoch 8/9\n",
      "3989/3989 - 32s - loss: 0.6536\n",
      "Epoch 9/9\n",
      "3989/3989 - 32s - loss: 0.6527\n",
      "Epoch 1/120\n",
      "3989/3989 - 30s - loss: 0.9617 - decoded_loss: 0.2848 - target_out_loss: 0.6769\n",
      "Epoch 2/120\n",
      "3989/3989 - 29s - loss: 0.8248 - decoded_loss: 0.1701 - target_out_loss: 0.6547\n",
      "Epoch 3/120\n",
      "3989/3989 - 30s - loss: 0.8123 - decoded_loss: 0.1582 - target_out_loss: 0.6540\n",
      "Epoch 4/120\n",
      "3989/3989 - 29s - loss: 0.8069 - decoded_loss: 0.1535 - target_out_loss: 0.6534\n",
      "Epoch 5/120\n",
      "3989/3989 - 30s - loss: 0.8040 - decoded_loss: 0.1512 - target_out_loss: 0.6528\n",
      "Epoch 6/120\n",
      "3989/3989 - 30s - loss: 0.8024 - decoded_loss: 0.1497 - target_out_loss: 0.6527\n",
      "Epoch 7/120\n",
      "3989/3989 - 30s - loss: 0.8013 - decoded_loss: 0.1487 - target_out_loss: 0.6526\n",
      "Epoch 8/120\n",
      "3989/3989 - 29s - loss: 0.8003 - decoded_loss: 0.1478 - target_out_loss: 0.6525\n",
      "Epoch 9/120\n",
      "3989/3989 - 29s - loss: 0.7996 - decoded_loss: 0.1473 - target_out_loss: 0.6522\n",
      "Epoch 10/120\n",
      "3989/3989 - 29s - loss: 0.7991 - decoded_loss: 0.1469 - target_out_loss: 0.6522\n",
      "Epoch 11/120\n",
      "3989/3989 - 29s - loss: 0.7988 - decoded_loss: 0.1466 - target_out_loss: 0.6522\n",
      "Epoch 12/120\n",
      "3989/3989 - 29s - loss: 0.7991 - decoded_loss: 0.1468 - target_out_loss: 0.6522\n",
      "Epoch 13/120\n",
      "3989/3989 - 29s - loss: 0.7985 - decoded_loss: 0.1464 - target_out_loss: 0.6521\n",
      "Epoch 14/120\n",
      "3989/3989 - 29s - loss: 0.7984 - decoded_loss: 0.1463 - target_out_loss: 0.6521\n",
      "Epoch 15/120\n",
      "3989/3989 - 29s - loss: 0.7984 - decoded_loss: 0.1464 - target_out_loss: 0.6520\n",
      "Epoch 16/120\n",
      "3989/3989 - 29s - loss: 0.7984 - decoded_loss: 0.1464 - target_out_loss: 0.6521\n",
      "Epoch 17/120\n",
      "3989/3989 - 29s - loss: 0.7982 - decoded_loss: 0.1463 - target_out_loss: 0.6520\n",
      "Epoch 18/120\n",
      "3989/3989 - 29s - loss: 0.7984 - decoded_loss: 0.1465 - target_out_loss: 0.6520\n",
      "Epoch 19/120\n",
      "3989/3989 - 29s - loss: 0.7983 - decoded_loss: 0.1464 - target_out_loss: 0.6520\n",
      "Epoch 20/120\n",
      "3989/3989 - 29s - loss: 0.7986 - decoded_loss: 0.1464 - target_out_loss: 0.6522\n",
      "Epoch 21/120\n",
      "3989/3989 - 29s - loss: 0.7982 - decoded_loss: 0.1464 - target_out_loss: 0.6519\n",
      "Epoch 22/120\n",
      "3989/3989 - 29s - loss: 0.7987 - decoded_loss: 0.1468 - target_out_loss: 0.6519\n",
      "Epoch 23/120\n",
      "3989/3989 - 29s - loss: 0.7983 - decoded_loss: 0.1466 - target_out_loss: 0.6517\n",
      "Epoch 24/120\n",
      "3989/3989 - 29s - loss: 0.7985 - decoded_loss: 0.1466 - target_out_loss: 0.6519\n",
      "Epoch 25/120\n",
      "3989/3989 - 30s - loss: 0.7985 - decoded_loss: 0.1465 - target_out_loss: 0.6519\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 26/120\n",
      "3989/3989 - 28s - loss: 0.7980 - decoded_loss: 0.1442 - target_out_loss: 0.6538\n",
      "Epoch 27/120\n",
      "3989/3989 - 28s - loss: 0.7969 - decoded_loss: 0.1432 - target_out_loss: 0.6537\n",
      "Epoch 28/120\n",
      "3989/3989 - 29s - loss: 0.7964 - decoded_loss: 0.1428 - target_out_loss: 0.6536\n",
      "Epoch 29/120\n",
      "3989/3989 - 29s - loss: 0.7963 - decoded_loss: 0.1427 - target_out_loss: 0.6536\n",
      "Epoch 30/120\n",
      "3989/3989 - 29s - loss: 0.7961 - decoded_loss: 0.1425 - target_out_loss: 0.6536\n",
      "Epoch 31/120\n",
      "3989/3989 - 29s - loss: 0.7961 - decoded_loss: 0.1425 - target_out_loss: 0.6536\n",
      "Epoch 32/120\n",
      "3989/3989 - 28s - loss: 0.7961 - decoded_loss: 0.1426 - target_out_loss: 0.6535\n",
      "Epoch 33/120\n",
      "3989/3989 - 29s - loss: 0.7960 - decoded_loss: 0.1426 - target_out_loss: 0.6534\n",
      "Epoch 34/120\n",
      "3989/3989 - 29s - loss: 0.7960 - decoded_loss: 0.1426 - target_out_loss: 0.6535\n",
      "Epoch 35/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1424 - target_out_loss: 0.6534\n",
      "Epoch 36/120\n",
      "3989/3989 - 29s - loss: 0.7957 - decoded_loss: 0.1422 - target_out_loss: 0.6535\n",
      "Epoch 37/120\n",
      "3989/3989 - 29s - loss: 0.7957 - decoded_loss: 0.1422 - target_out_loss: 0.6535\n",
      "Epoch 38/120\n",
      "3989/3989 - 29s - loss: 0.7956 - decoded_loss: 0.1423 - target_out_loss: 0.6533\n",
      "Epoch 39/120\n",
      "3989/3989 - 29s - loss: 0.7955 - decoded_loss: 0.1422 - target_out_loss: 0.6533\n",
      "Epoch 40/120\n",
      "3989/3989 - 29s - loss: 0.7956 - decoded_loss: 0.1421 - target_out_loss: 0.6535\n",
      "Epoch 41/120\n",
      "3989/3989 - 28s - loss: 0.7954 - decoded_loss: 0.1420 - target_out_loss: 0.6534\n",
      "Epoch 42/120\n",
      "3989/3989 - 29s - loss: 0.7954 - decoded_loss: 0.1420 - target_out_loss: 0.6533\n",
      "Epoch 43/120\n",
      "3989/3989 - 29s - loss: 0.7955 - decoded_loss: 0.1422 - target_out_loss: 0.6533\n",
      "Epoch 44/120\n",
      "3989/3989 - 29s - loss: 0.7955 - decoded_loss: 0.1423 - target_out_loss: 0.6533\n",
      "Epoch 45/120\n",
      "3989/3989 - 29s - loss: 0.7957 - decoded_loss: 0.1424 - target_out_loss: 0.6533\n",
      "Epoch 46/120\n",
      "3989/3989 - 29s - loss: 0.7957 - decoded_loss: 0.1423 - target_out_loss: 0.6533\n",
      "Epoch 47/120\n",
      "3989/3989 - 29s - loss: 0.7955 - decoded_loss: 0.1423 - target_out_loss: 0.6533\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 48/120\n",
      "3989/3989 - 28s - loss: 0.7985 - decoded_loss: 0.1433 - target_out_loss: 0.6552\n",
      "Epoch 49/120\n",
      "3989/3989 - 29s - loss: 0.7968 - decoded_loss: 0.1419 - target_out_loss: 0.6550\n",
      "Epoch 50/120\n",
      "3989/3989 - 29s - loss: 0.7964 - decoded_loss: 0.1415 - target_out_loss: 0.6550\n",
      "Epoch 51/120\n",
      "3989/3989 - 29s - loss: 0.7960 - decoded_loss: 0.1411 - target_out_loss: 0.6549\n",
      "Epoch 52/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1409 - target_out_loss: 0.6549\n",
      "Epoch 53/120\n",
      "3989/3989 - 29s - loss: 0.7955 - decoded_loss: 0.1406 - target_out_loss: 0.6549\n",
      "Epoch 54/120\n",
      "3989/3989 - 30s - loss: 0.7952 - decoded_loss: 0.1403 - target_out_loss: 0.6549\n",
      "Epoch 1/9\n",
      "3989/3989 - 33s - loss: 0.6718\n",
      "Epoch 2/9\n",
      "3989/3989 - 32s - loss: 0.6585\n",
      "Epoch 3/9\n",
      "3989/3989 - 31s - loss: 0.6574\n",
      "Epoch 4/9\n",
      "3989/3989 - 31s - loss: 0.6569\n",
      "Epoch 5/9\n",
      "3989/3989 - 31s - loss: 0.6563\n",
      "Epoch 6/9\n",
      "3989/3989 - 31s - loss: 0.6552\n",
      "Epoch 7/9\n",
      "3989/3989 - 31s - loss: 0.6542\n",
      "Epoch 8/9\n",
      "3989/3989 - 31s - loss: 0.6533\n",
      "Epoch 9/9\n",
      "3989/3989 - 32s - loss: 0.6523\n",
      "Epoch 1/120\n",
      "3989/3989 - 30s - loss: 0.9717 - decoded_loss: 0.2935 - target_out_loss: 0.6782\n",
      "Epoch 2/120\n",
      "3989/3989 - 29s - loss: 0.8257 - decoded_loss: 0.1707 - target_out_loss: 0.6550\n",
      "Epoch 3/120\n",
      "3989/3989 - 29s - loss: 0.8126 - decoded_loss: 0.1586 - target_out_loss: 0.6540\n",
      "Epoch 4/120\n",
      "3989/3989 - 29s - loss: 0.8071 - decoded_loss: 0.1537 - target_out_loss: 0.6534\n",
      "Epoch 5/120\n",
      "3989/3989 - 29s - loss: 0.8041 - decoded_loss: 0.1514 - target_out_loss: 0.6528\n",
      "Epoch 6/120\n",
      "3989/3989 - 29s - loss: 0.8024 - decoded_loss: 0.1498 - target_out_loss: 0.6526\n",
      "Epoch 7/120\n",
      "3989/3989 - 30s - loss: 0.8013 - decoded_loss: 0.1487 - target_out_loss: 0.6526\n",
      "Epoch 8/120\n",
      "3989/3989 - 31s - loss: 0.8001 - decoded_loss: 0.1478 - target_out_loss: 0.6523\n",
      "Epoch 9/120\n",
      "3989/3989 - 30s - loss: 0.7995 - decoded_loss: 0.1473 - target_out_loss: 0.6522\n",
      "Epoch 10/120\n",
      "3989/3989 - 30s - loss: 0.7992 - decoded_loss: 0.1471 - target_out_loss: 0.6522\n",
      "Epoch 11/120\n",
      "3989/3989 - 31s - loss: 0.7990 - decoded_loss: 0.1468 - target_out_loss: 0.6521\n",
      "Epoch 12/120\n",
      "3989/3989 - 31s - loss: 0.7990 - decoded_loss: 0.1468 - target_out_loss: 0.6522\n",
      "Epoch 13/120\n",
      "3989/3989 - 31s - loss: 0.7987 - decoded_loss: 0.1466 - target_out_loss: 0.6521\n",
      "Epoch 14/120\n",
      "3989/3989 - 31s - loss: 0.7984 - decoded_loss: 0.1465 - target_out_loss: 0.6519\n",
      "Epoch 15/120\n",
      "3989/3989 - 31s - loss: 0.7985 - decoded_loss: 0.1465 - target_out_loss: 0.6520\n",
      "Epoch 16/120\n",
      "3989/3989 - 29s - loss: 0.7987 - decoded_loss: 0.1467 - target_out_loss: 0.6520\n",
      "Epoch 17/120\n",
      "3989/3989 - 29s - loss: 0.7984 - decoded_loss: 0.1465 - target_out_loss: 0.6519\n",
      "Epoch 18/120\n",
      "3989/3989 - 30s - loss: 0.7984 - decoded_loss: 0.1465 - target_out_loss: 0.6519\n",
      "Epoch 19/120\n",
      "3989/3989 - 29s - loss: 0.7983 - decoded_loss: 0.1464 - target_out_loss: 0.6519\n",
      "Epoch 20/120\n",
      "3989/3989 - 29s - loss: 0.7987 - decoded_loss: 0.1467 - target_out_loss: 0.6520\n",
      "Epoch 21/120\n",
      "3989/3989 - 30s - loss: 0.7985 - decoded_loss: 0.1464 - target_out_loss: 0.6521\n",
      "Epoch 22/120\n",
      "3989/3989 - 30s - loss: 0.7985 - decoded_loss: 0.1464 - target_out_loss: 0.6521\n",
      "Epoch 23/120\n",
      "3989/3989 - 30s - loss: 0.7984 - decoded_loss: 0.1467 - target_out_loss: 0.6517\n",
      "Epoch 24/120\n",
      "3989/3989 - 29s - loss: 0.7985 - decoded_loss: 0.1468 - target_out_loss: 0.6517\n",
      "Epoch 25/120\n",
      "3989/3989 - 30s - loss: 0.7986 - decoded_loss: 0.1466 - target_out_loss: 0.6520\n",
      "Epoch 26/120\n",
      "3989/3989 - 30s - loss: 0.7987 - decoded_loss: 0.1468 - target_out_loss: 0.6519\n",
      "Epoch 27/120\n",
      "3989/3989 - 29s - loss: 0.7985 - decoded_loss: 0.1466 - target_out_loss: 0.6518\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 28/120\n",
      "3989/3989 - 29s - loss: 0.7981 - decoded_loss: 0.1442 - target_out_loss: 0.6539\n",
      "Epoch 29/120\n",
      "3989/3989 - 30s - loss: 0.7970 - decoded_loss: 0.1434 - target_out_loss: 0.6536\n",
      "Epoch 30/120\n",
      "3989/3989 - 28s - loss: 0.7965 - decoded_loss: 0.1429 - target_out_loss: 0.6536\n",
      "Epoch 31/120\n",
      "3989/3989 - 29s - loss: 0.7965 - decoded_loss: 0.1429 - target_out_loss: 0.6536\n",
      "Epoch 32/120\n",
      "3989/3989 - 29s - loss: 0.7961 - decoded_loss: 0.1427 - target_out_loss: 0.6534\n",
      "Epoch 33/120\n",
      "3989/3989 - 29s - loss: 0.7963 - decoded_loss: 0.1429 - target_out_loss: 0.6534\n",
      "Epoch 34/120\n",
      "3989/3989 - 29s - loss: 0.7962 - decoded_loss: 0.1427 - target_out_loss: 0.6535\n",
      "Epoch 35/120\n",
      "3989/3989 - 29s - loss: 0.7962 - decoded_loss: 0.1426 - target_out_loss: 0.6536\n",
      "Epoch 36/120\n",
      "3989/3989 - 28s - loss: 0.7960 - decoded_loss: 0.1426 - target_out_loss: 0.6534\n",
      "Epoch 37/120\n",
      "3989/3989 - 29s - loss: 0.7959 - decoded_loss: 0.1425 - target_out_loss: 0.6534\n",
      "Epoch 38/120\n",
      "3989/3989 - 29s - loss: 0.7959 - decoded_loss: 0.1425 - target_out_loss: 0.6534\n",
      "Epoch 39/120\n",
      "3989/3989 - 29s - loss: 0.7959 - decoded_loss: 0.1425 - target_out_loss: 0.6534\n",
      "Epoch 40/120\n",
      "3989/3989 - 29s - loss: 0.7959 - decoded_loss: 0.1426 - target_out_loss: 0.6532\n",
      "Epoch 41/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1424 - target_out_loss: 0.6533\n",
      "Epoch 42/120\n",
      "3989/3989 - 29s - loss: 0.7957 - decoded_loss: 0.1425 - target_out_loss: 0.6532\n",
      "Epoch 43/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1425 - target_out_loss: 0.6533\n",
      "Epoch 44/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1425 - target_out_loss: 0.6533\n",
      "Epoch 45/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1425 - target_out_loss: 0.6534\n",
      "Epoch 46/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1427 - target_out_loss: 0.6531\n",
      "Epoch 47/120\n",
      "3989/3989 - 29s - loss: 0.7957 - decoded_loss: 0.1425 - target_out_loss: 0.6532\n",
      "Epoch 48/120\n",
      "3989/3989 - 29s - loss: 0.7961 - decoded_loss: 0.1427 - target_out_loss: 0.6534\n",
      "Epoch 49/120\n",
      "3989/3989 - 29s - loss: 0.7958 - decoded_loss: 0.1426 - target_out_loss: 0.6532\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 50/120\n",
      "3989/3989 - 29s - loss: 0.7986 - decoded_loss: 0.1437 - target_out_loss: 0.6549\n",
      "Epoch 51/120\n",
      "3989/3989 - 30s - loss: 0.7970 - decoded_loss: 0.1421 - target_out_loss: 0.6549\n",
      "Epoch 1/9\n",
      "3989/3989 - 33s - loss: 0.6742\n",
      "Epoch 2/9\n",
      "3989/3989 - 31s - loss: 0.6593\n",
      "Epoch 3/9\n",
      "3989/3989 - 32s - loss: 0.6583\n",
      "Epoch 4/9\n",
      "3989/3989 - 31s - loss: 0.6576\n",
      "Epoch 5/9\n",
      "3989/3989 - 32s - loss: 0.6565\n",
      "Epoch 6/9\n",
      "3989/3989 - 32s - loss: 0.6556\n",
      "Epoch 7/9\n",
      "3989/3989 - 32s - loss: 0.6550\n",
      "Epoch 8/9\n",
      "3989/3989 - 32s - loss: 0.6540\n",
      "Epoch 9/9\n",
      "3989/3989 - 31s - loss: 0.6534\n"
     ]
    }
   ],
   "source": [
    "def build_encoder(input_dim, noise_rate=0.05):\n",
    "    ori_input = Input(shape=(input_dim,), dtype='float16')\n",
    "    encode = layers.BatchNormalization()(ori_input)\n",
    "    encode = layers.GaussianNoise(stddev=noise_rate)(encode)\n",
    "    encode = layers.Dense(256)(encode)\n",
    "    encode = Mish()(encode)\n",
    "    decode = layers.Dropout(0.1)(encode)\n",
    "    decode = layers.Dense(input_dim, name='decoded')(decode)\n",
    "    x = layers.Dense(265, use_bias=False)(decode)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(1, name='target_out')(x)\n",
    "\n",
    "    encoder = models.Model(inputs=[ori_input], outputs=[encode])\n",
    "    autoencoder = models.Model(inputs=[ori_input], outputs=[decode, x])\n",
    "    autoencoder.compile(optimizer=optimizers.Adam(learning_rate=cfg.enco_LR),\n",
    "                        loss={'decoded': losses.MeanSquaredError(),\n",
    "                              'target_out': losses.MeanSquaredError()})\n",
    "    return autoencoder, encoder\n",
    "\n",
    "def build_model(encoder):\n",
    "    ox_input = Input(shape=(cfg.input_dim,), dtype='float16')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=cfg.mlp_LR),\n",
    "                  loss=losses.MeanSquaredError())\n",
    "    return model\n",
    "\n",
    "def make_dataset(feature, y, batch_size=512, mode=\"train\", to='mlp'):\n",
    "    if to == 'mlp':\n",
    "        ds = tf.data.Dataset.from_tensor_slices((feature, y))\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((feature, (feature, y)))\n",
    "    if mode == \"train\":\n",
    "        ds = ds.shuffle(4096, seed=cfg.train_shuffle_seed, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "def get_encoder(mode='new', train_ds=None, test_ds=None, the_callback=None):\n",
    "    if mode == 'freeze':\n",
    "        autoencoder, encoder = build_encoder(cfg.input_dim)\n",
    "        encoder.load_weights(cfg.enco_weights_dir)\n",
    "    else:\n",
    "        assert the_callback != None, 'callbacks 不能是 None!'\n",
    "        autoencoder, encoder = build_encoder(cfg.input_dim, noise_rate=cfg.enco_noise_rate)\n",
    "        if mode == 'new':\n",
    "            autoencoder.fit(train_ds,\n",
    "                            epochs=cfg.enco_epoch,\n",
    "                            callbacks=the_callback,\n",
    "                           verbose=2)\n",
    "            encoder.save_weights(cfg.save_encoder_dir())\n",
    "        elif mode == 'cv':\n",
    "                autoencoder.fit(train_ds,\n",
    "                                validation_data=test_ds,\n",
    "                                epochs=cfg.enco_epoch,\n",
    "                                callbacks=the_callback,\n",
    "                                verbose=2)\n",
    "    encoder.trainable = False\n",
    "    return encoder\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    if cfg.full_train:\n",
    "        if cfg.freeze_enco:\n",
    "            encoder = get_encoder(mode='freeze')\n",
    "        else:\n",
    "            callback = [callbacks.ReduceLROnPlateau(monitor='loss', patience=8, factor=0.6, verbose=1),\n",
    "                        callbacks.EarlyStopping(monitor='loss', patience=15, restore_best_weights=True, min_delta=0.0004)]\n",
    "            train_ds = make_dataset(fea_data, target, batch_size=cfg.enco_batch_size, to='encoder')\n",
    "            encoder = get_encoder(mode='new', train_ds=train_ds, the_callback=callback)\n",
    "            del train_ds\n",
    "            gc.collect()\n",
    "            \n",
    "            \n",
    "            time.sleep(15)\n",
    "            \n",
    "            \n",
    "        callback = [callbacks.ReduceLROnPlateau(monitor='loss',\n",
    "                                                patience=cfg.cb_rlrp_patience,\n",
    "                                                factor=cfg.cb_rlrp_factor, verbose=1),\n",
    "                    callbacks.EarlyStopping(monitor='loss',\n",
    "                                            patience=cfg.cb_es_patience,\n",
    "                                            restore_best_weights=False)]\n",
    "        \n",
    "        the_model = build_model(encoder)\n",
    "        the_model.compile(optimizer=optimizers.Adam(learning_rate=cfg.mlp_LR),\n",
    "                          loss=losses.MeanSquaredError())\n",
    "        train_ds = make_dataset(fea_data, target, batch_size=cfg.mlp_batch_size)\n",
    "        the_model.fit(train_ds,\n",
    "                      epochs=cfg.mlp_epoch,\n",
    "                      callbacks=callback,\n",
    "                      verbose=2)\n",
    "        new_model.append(the_model)\n",
    "\n",
    "        del train_ds\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "        \n",
    "        time.sleep(15)\n",
    "        \n",
    "        \n",
    "\n",
    "del fea_data, target\n",
    "gc.collect()\n",
    "K.clear_session()\n",
    "\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "316a470d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:56:46.666602Z",
     "iopub.status.busy": "2022-04-19T13:56:46.665900Z",
     "iopub.status.idle": "2022-04-19T13:58:11.792710Z",
     "shell.execute_reply": "2022-04-19T13:58:11.791771Z",
     "shell.execute_reply.started": "2022-04-18T16:45:59.303293Z"
    },
    "papermill": {
     "duration": 85.252138,
     "end_time": "2022-04-19T13:58:11.792863",
     "exception": false,
     "start_time": "2022-04-19T13:56:46.540725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet('../input/ubiquant-parquet/train_low_mem.parquet')\n",
    "data = data.drop(columns=['time_id', 'row_id', 'investment_id', 'target']).values\n",
    "\n",
    "gc.collect()\n",
    "time.sleep(10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "del data\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e761470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:12.031517Z",
     "iopub.status.busy": "2022-04-19T13:58:12.030767Z",
     "iopub.status.idle": "2022-04-19T13:58:12.032927Z",
     "shell.execute_reply": "2022-04-19T13:58:12.033330Z",
     "shell.execute_reply.started": "2022-04-18T16:47:27.60045Z"
    },
    "papermill": {
     "duration": 0.126836,
     "end_time": "2022-04-19T13:58:12.033466",
     "exception": false,
     "start_time": "2022-04-19T13:58:11.906630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = 300\n",
    "def build_encoder(input_dim, noise_rate=0.05):\n",
    "    ori_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    encode = layers.BatchNormalization()(ori_input)\n",
    "    encode = layers.GaussianNoise(stddev=noise_rate)(encode)\n",
    "    encode = layers.Dense(256)(encode)\n",
    "    encode = Mish()(encode)\n",
    "    decode = layers.Dropout(0.2)(encode)\n",
    "    decode = layers.Dense(input_dim, name='decoded')(decode)\n",
    "    x = layers.Dense(265, use_bias=False)(decode)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(1, name='target_out')(x)\n",
    "\n",
    "    encoder = models.Model(inputs=[ori_input], outputs=[encode])\n",
    "    autoencoder = models.Model(inputs=[ori_input], outputs=[decode, x])\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd4590e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:12.265740Z",
     "iopub.status.busy": "2022-04-19T13:58:12.264959Z",
     "iopub.status.idle": "2022-04-19T13:58:12.267433Z",
     "shell.execute_reply": "2022-04-19T13:58:12.266960Z",
     "shell.execute_reply.started": "2022-04-18T16:47:27.616932Z"
    },
    "papermill": {
     "duration": 0.121531,
     "end_time": "2022-04-19T13:58:12.267543",
     "exception": false,
     "start_time": "2022-04-19T13:58:12.146012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_encoder_0(input_dim, noise_rate=0.05):\n",
    "    ori_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    encode = layers.BatchNormalization()(ori_input)\n",
    "    encode = layers.GaussianNoise(stddev=noise_rate)(encode)\n",
    "    encode = layers.Dense(256)(encode)\n",
    "    encode = Mish()(encode)\n",
    "    decode = layers.Dropout(0.1)(encode)\n",
    "    decode = layers.Dense(input_dim, name='decoded')(decode)\n",
    "    x = layers.Dense(265, use_bias=False)(decode)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(1, name='target')(x)\n",
    "\n",
    "    encoder = models.Model(inputs=[ori_input], outputs=[encode])\n",
    "    autoencoder = models.Model(inputs=[ori_input], outputs=[decode, x])\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0142d558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:12.502844Z",
     "iopub.status.busy": "2022-04-19T13:58:12.502030Z",
     "iopub.status.idle": "2022-04-19T13:58:12.504026Z",
     "shell.execute_reply": "2022-04-19T13:58:12.504416Z",
     "shell.execute_reply.started": "2022-04-18T16:47:27.630391Z"
    },
    "papermill": {
     "duration": 0.124584,
     "end_time": "2022-04-19T13:58:12.504545",
     "exception": false,
     "start_time": "2022-04-19T13:58:12.379961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_0(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11fd5c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:12.742542Z",
     "iopub.status.busy": "2022-04-19T13:58:12.741840Z",
     "iopub.status.idle": "2022-04-19T13:58:12.744385Z",
     "shell.execute_reply": "2022-04-19T13:58:12.743965Z",
     "shell.execute_reply.started": "2022-04-18T16:47:27.644357Z"
    },
    "papermill": {
     "duration": 0.128111,
     "end_time": "2022-04-19T13:58:12.744493",
     "exception": false,
     "start_time": "2022-04-19T13:58:12.616382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_1(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d451bf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:12.977632Z",
     "iopub.status.busy": "2022-04-19T13:58:12.976926Z",
     "iopub.status.idle": "2022-04-19T13:58:12.979047Z",
     "shell.execute_reply": "2022-04-19T13:58:12.979455Z",
     "shell.execute_reply.started": "2022-04-18T16:47:27.660459Z"
    },
    "papermill": {
     "duration": 0.123775,
     "end_time": "2022-04-19T13:58:12.979583",
     "exception": false,
     "start_time": "2022-04-19T13:58:12.855808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_2(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea8cbbe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:13.213459Z",
     "iopub.status.busy": "2022-04-19T13:58:13.212777Z",
     "iopub.status.idle": "2022-04-19T13:58:13.215316Z",
     "shell.execute_reply": "2022-04-19T13:58:13.214869Z",
     "shell.execute_reply.started": "2022-04-18T16:47:27.675329Z"
    },
    "papermill": {
     "duration": 0.123496,
     "end_time": "2022-04-19T13:58:13.215422",
     "exception": false,
     "start_time": "2022-04-19T13:58:13.091926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_bigdrop_1(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca704741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:13.450296Z",
     "iopub.status.busy": "2022-04-19T13:58:13.449489Z",
     "iopub.status.idle": "2022-04-19T13:58:13.451459Z",
     "shell.execute_reply": "2022-04-19T13:58:13.451828Z",
     "shell.execute_reply.started": "2022-04-18T16:47:27.690776Z"
    },
    "papermill": {
     "duration": 0.124569,
     "end_time": "2022-04-19T13:58:13.451952",
     "exception": false,
     "start_time": "2022-04-19T13:58:13.327383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model_bigdrop(encoder):\n",
    "    ox_input = Input(shape=(input_dim,), dtype='float32')\n",
    "    ox_enco = encoder(ox_input)\n",
    "\n",
    "    x = layers.Dense(512, use_bias=False)(ox_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = Mish()(x)\n",
    "\n",
    "    x = layers.Concatenate()([x, ox_enco])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Mish()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=[ox_input], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bace7a24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:13.679528Z",
     "iopub.status.busy": "2022-04-19T13:58:13.678918Z",
     "iopub.status.idle": "2022-04-19T13:58:13.702345Z",
     "shell.execute_reply": "2022-04-19T13:58:13.701891Z",
     "shell.execute_reply.started": "2022-04-18T16:47:27.714587Z"
    },
    "papermill": {
     "duration": 0.138302,
     "end_time": "2022-04-19T13:58:13.702456",
     "exception": false,
     "start_time": "2022-04-19T13:58:13.564154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ubiquant\n",
    "env = ubiquant.make_env()\n",
    "iter_test = env.iter_test()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e578a395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:13.936816Z",
     "iopub.status.busy": "2022-04-19T13:58:13.936058Z",
     "iopub.status.idle": "2022-04-19T13:58:20.716785Z",
     "shell.execute_reply": "2022-04-19T13:58:20.715949Z",
     "shell.execute_reply.started": "2022-04-18T16:47:27.752056Z"
    },
    "papermill": {
     "duration": 6.902051,
     "end_time": "2022-04-19T13:58:20.716914",
     "exception": false,
     "start_time": "2022-04-19T13:58:13.814863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "weights = ['../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-1-ep8-loss0.8170.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-10-ep8-loss0.8171.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-11-ep8-loss0.8174.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-12-ep8-loss0.8181.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-2-ep8-loss0.8170.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-3-ep8-loss0.8181.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-4-ep8-loss0.8191.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-5-ep8-loss0.8176.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-6-ep8-loss0.8170.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-7-ep8-loss0.8175.h5',\n",
    "          '../input/ubiquantbigdropbt512weights/origin-bigdrop-bt512-test-9-ep8-loss0.8182.h5',\n",
    "          \n",
    "           '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-1-ep8-loss0.8173.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-10-ep8-loss0.8175.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-11-ep8-loss0.8181.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-12-ep8-loss0.8185.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-2-ep8-loss0.8176.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-3-ep8-loss0.8182.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-4-ep8-loss0.8178.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-5-ep8-loss0.8183.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-6-ep8-loss0.8185.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-7-ep8-loss0.8171.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-8-ep8-loss0.8176.h5',\n",
    "          '../input/ubiquantbigdrop1bt512weights/origin-bigdrop-1-bt512-test-9-ep8-loss0.8172.h5']\n",
    "\n",
    "model_bigdrop_bt512 = []\n",
    "for w in weights:\n",
    "    autoencoder, encoder = build_encoder_0(input_dim)\n",
    "    encoder.trainable = False\n",
    "    model_temp = build_model_bigdrop(encoder)\n",
    "    model_temp.load_weights(w)\n",
    "    model_bigdrop_bt512.append(model_temp)\n",
    "print(len(model_bigdrop_bt512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c36a0dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:20.952806Z",
     "iopub.status.busy": "2022-04-19T13:58:20.952006Z",
     "iopub.status.idle": "2022-04-19T13:58:28.623588Z",
     "shell.execute_reply": "2022-04-19T13:58:28.624095Z",
     "shell.execute_reply.started": "2022-04-18T16:47:34.864496Z"
    },
    "papermill": {
     "duration": 7.794258,
     "end_time": "2022-04-19T13:58:28.624275",
     "exception": false,
     "start_time": "2022-04-19T13:58:20.830017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "weights = ['../input/ubiquantbigdropbt1024weights/fulltr-bigdrop-origin-bt1024-test-1-ep9-loss0.8211.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-10-ep9-loss0.8189.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-2-ep9-loss0.8203.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-3-ep9-loss0.8210.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-4-ep9-loss0.8219.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-5-ep9-loss0.8202.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-6-ep9-loss0.8196.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-7-ep9-loss0.8201.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-8-ep9-loss0.8198.h5',\n",
    "          '../input/ubiquantbigdropbt1024weights/origin-bigdrop-bt1024-test-9-ep9-loss0.8196.h5',\n",
    "           \n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-1-ep9-loss0.8200.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-10-ep9-loss0.8206.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-11-ep9-loss0.8205.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-12-ep9-loss0.8193.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-13-ep9-loss0.8211.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-14-ep9-loss0.8209.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-2-ep9-loss0.8217.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-3-ep9-loss0.8200.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-4-ep9-loss0.8191.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-5-ep9-loss0.8198.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-6-ep9-loss0.8203.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-7-ep9-loss0.8195.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-8-ep9-loss0.8198.h5',\n",
    "          '../input/ubiquantbigdrop1bt1024weights/origin-bigdrop-1-bt1024-test-9-ep9-loss0.8200.h5']\n",
    "\n",
    "model_bigdrop_bt1024 = []\n",
    "for w in weights:\n",
    "    autoencoder, encoder = build_encoder_0(input_dim)\n",
    "    encoder.trainable = False\n",
    "    model_temp = build_model_bigdrop(encoder)\n",
    "    model_temp.load_weights(w)\n",
    "    model_bigdrop_bt1024.append(model_temp)\n",
    "print(len(model_bigdrop_bt1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24abff0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:28.878949Z",
     "iopub.status.busy": "2022-04-19T13:58:28.877272Z",
     "iopub.status.idle": "2022-04-19T13:58:35.608040Z",
     "shell.execute_reply": "2022-04-19T13:58:35.608841Z",
     "shell.execute_reply.started": "2022-04-18T16:47:42.65789Z"
    },
    "papermill": {
     "duration": 6.85873,
     "end_time": "2022-04-19T13:58:35.609016",
     "exception": false,
     "start_time": "2022-04-19T13:58:28.750286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "weights = ['../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-1-ep9-loss0.8195.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-10-ep9-loss0.8197.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-11-ep9-loss0.8204.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-12-ep9-loss0.8198.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-13-ep9-loss0.8210.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-14-ep9-loss0.8192.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-15-ep9-loss0.8188.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-16-ep9-loss0.8202.h5',\n",
    "#           '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-17-ep9-loss0.8217.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-18-ep9-loss0.8198.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-19-ep9-loss0.8206.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-2-ep9-loss0.8202.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-20-ep9-loss0.8193.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-21-ep9-loss0.8201.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-22-ep9-loss0.8200.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-23-ep9-loss0.8195.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-24-ep9-loss0.8213.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-25-ep9-loss0.8190.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-3-ep9-loss0.8199.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-4-ep9-loss0.8200.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-5-ep9-loss0.8212.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-6-ep9-loss0.8199.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-7-ep9-loss0.8206.h5',\n",
    "          '../input/ubiquantbigdrop-new-bt1024weights/origin-bigdrop-1-bt1024-test-9-ep9-loss0.8190.h5']\n",
    "\n",
    "model_bigdrop_1_bt1024 = []\n",
    "for w in weights:\n",
    "    autoencoder, encoder = build_encoder_0(input_dim)\n",
    "    encoder.trainable = False\n",
    "    model_temp = build_model_bigdrop_1(encoder)\n",
    "    model_temp.load_weights(w)\n",
    "    model_bigdrop_1_bt1024.append(model_temp)\n",
    "print(len(model_bigdrop_1_bt1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fc98a0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:35.846110Z",
     "iopub.status.busy": "2022-04-19T13:58:35.845294Z",
     "iopub.status.idle": "2022-04-19T13:58:37.330851Z",
     "shell.execute_reply": "2022-04-19T13:58:37.331307Z",
     "shell.execute_reply.started": "2022-04-18T16:47:50.172359Z"
    },
    "papermill": {
     "duration": 1.608252,
     "end_time": "2022-04-19T13:58:37.331462",
     "exception": false,
     "start_time": "2022-04-19T13:58:35.723210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "weights = ['../input/ubiquanttts6foldweights/origin-bigdrop-test-1_5.h5',\n",
    "          '../input/ubiquanttts6foldweights/origin-bigdrop-test-2_5.h5',\n",
    "          '../input/ubiquanttts6foldweights/origin-bigdrop-test-3_5.h5',\n",
    "          '../input/ubiquanttts6foldweights/origin-bigdrop-test-4_5.h5']\n",
    "\n",
    "model_bigdrop_fold6 = []\n",
    "\n",
    "autoencoder, encoder = build_encoder_0(input_dim)\n",
    "encoder.trainable = False\n",
    "model_temp = build_model_bigdrop_1(encoder)\n",
    "model_temp.load_weights('../input/ubiquanttts6foldweights/origin-bigdrop-1-test-1_5.h5')\n",
    "model_bigdrop_fold6.append(model_temp)\n",
    "\n",
    "for w in weights:\n",
    "    autoencoder, encoder = build_encoder_0(input_dim)\n",
    "    encoder.trainable = False\n",
    "    model_temp = build_model_bigdrop(encoder)\n",
    "    model_temp.load_weights(w)\n",
    "    model_bigdrop_fold6.append(model_temp)\n",
    "print(len(model_bigdrop_fold6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "103d3c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:37.566868Z",
     "iopub.status.busy": "2022-04-19T13:58:37.566066Z",
     "iopub.status.idle": "2022-04-19T13:58:40.435559Z",
     "shell.execute_reply": "2022-04-19T13:58:40.435092Z",
     "shell.execute_reply.started": "2022-04-18T16:47:51.649655Z"
    },
    "papermill": {
     "duration": 2.990266,
     "end_time": "2022-04-19T13:58:40.435684",
     "exception": false,
     "start_time": "2022-04-19T13:58:37.445418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "weights = ['../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-1_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-2_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-3_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-4_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-5_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-6_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-7_13.h5',\n",
    "          '../input/ubiquantbigdrop14foldweights/origin-bigdrop-1-14fold-test-8_13.h5']\n",
    "\n",
    "model_bigdrop_fold14 = []\n",
    "for w in weights:\n",
    "    autoencoder, encoder = build_encoder_0(input_dim)\n",
    "    encoder.trainable = False\n",
    "    model_temp = build_model_bigdrop(encoder)\n",
    "    model_temp.load_weights(w)\n",
    "    model_bigdrop_fold14.append(model_temp)\n",
    "print(len(model_bigdrop_fold14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d08e9a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:40.669728Z",
     "iopub.status.busy": "2022-04-19T13:58:40.668937Z",
     "iopub.status.idle": "2022-04-19T13:58:41.284395Z",
     "shell.execute_reply": "2022-04-19T13:58:41.283873Z",
     "shell.execute_reply.started": "2022-04-18T16:47:54.368782Z"
    },
    "papermill": {
     "duration": 0.734424,
     "end_time": "2022-04-19T13:58:41.284523",
     "exception": false,
     "start_time": "2022-04-19T13:58:40.550099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder, encoder_0 = build_encoder(input_dim)\n",
    "encoder_0.trainable = False\n",
    "autoencoder, encoder_1 = build_encoder(input_dim)\n",
    "encoder_1.trainable = False\n",
    "autoencoder, encoder_2 = build_encoder(input_dim)\n",
    "encoder_2.trainable = False\n",
    "\n",
    "autoencoder, encoder_0_0 = build_encoder(input_dim)\n",
    "encoder_0_0.trainable = False\n",
    "autoencoder, encoder_0_2 = build_encoder(input_dim)\n",
    "encoder_0_2.trainable = False\n",
    "\n",
    "autoencoder, encoder_1_0 = build_encoder(input_dim)\n",
    "encoder_1_0.trainable = False\n",
    "\n",
    "autoencoder, encoder_2_0 = build_encoder(input_dim)\n",
    "encoder_2_0.trainable = False\n",
    "autoencoder, encoder_2_1 = build_encoder(input_dim)\n",
    "encoder_2_1.trainable = False\n",
    "autoencoder, encoder_2_2 = build_encoder(input_dim)\n",
    "encoder_2_2.trainable = False\n",
    "autoencoder, encoder_2_3 = build_encoder(input_dim)\n",
    "encoder_2_3.trainable = False\n",
    "autoencoder, encoder_2_4 = build_encoder(input_dim)\n",
    "encoder_2_4.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eda5181b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:41.527223Z",
     "iopub.status.busy": "2022-04-19T13:58:41.526337Z",
     "iopub.status.idle": "2022-04-19T13:58:44.266030Z",
     "shell.execute_reply": "2022-04-19T13:58:44.265565Z",
     "shell.execute_reply.started": "2022-04-18T16:47:55.021793Z"
    },
    "papermill": {
     "duration": 2.865593,
     "end_time": "2022-04-19T13:58:44.266183",
     "exception": false,
     "start_time": "2022-04-19T13:58:41.400590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#0.1521\n",
    "model_0 = build_model_0(encoder_0)\n",
    "model_0.load_weights('../input/ubiquantfulltrainsubweights/m0-fulltr-two-256-drop0.2-encodrop0.2-ep7-loss0.8171.h5')\n",
    "#0.1515\n",
    "model_0_0= build_model_0(encoder_0_0)\n",
    "model_0_0.load_weights('../input/ubiquantfulltrainsubweights/m0_0-0.1515-fulltr-two256drop-seed-1-test-3-ep7-loss0.8170.h5')\n",
    "#1532\n",
    "model_0_2= build_model_0(encoder_0_2)\n",
    "model_0_2.load_weights('../input/ubiquantfulltrainsubweights/m0_2_fulltr-two256drop-myloss-4-6-test-1-ep7-loss0.8179.h5')\n",
    "\n",
    "\n",
    "#1521-ep7\n",
    "model_1 = build_model_1(encoder_1)\n",
    "model_1.load_weights('../input/ubiquantfulltrainsubweights/m1-fulltr-256dropmove-encodrop0.2-ep7-loss0.8178.h5')\n",
    "#1520\n",
    "model_1_0 = build_model_1(encoder_1_0)\n",
    "model_1_0.load_weights('../input/ubiquantfulltrainsubweights/m1_0_fulltr-dropmove-myloss-4-6-test-1-ep7-loss0.8170.h5')\n",
    "\n",
    "#1523\n",
    "model_2 = build_model_2(encoder_2)\n",
    "model_2.load_weights('../input/ubiquantfulltrainsubweights/m2-fulltr-Mish-512_128-512-newenco-ep7-loss0.8178.h5')\n",
    "#1501\n",
    "model_2_0 = build_model_2(encoder_2_0)\n",
    "model_2_0.load_weights('../input/ubiquantfulltrainsubweights/m2_0_fulltr-origin-seed-1-test-3-ep7-loss0.8171.h5')\n",
    "#1514\n",
    "model_2_1 = build_model_2(encoder_2_1)\n",
    "model_2_1.load_weights('../input/ubiquantfulltrainsubweights/m2_1_fulltr-tfrecords-original-test-1-ep7-loss0.8189.h5')\n",
    "#1511\n",
    "model_2_2 = build_model_2(encoder_2_2)\n",
    "model_2_2.load_weights('../input/ubiquantfulltrainsubweights/m2_2_fulltr-origin-seed430-test-1-ep7-loss0.8179.h5')\n",
    "#1504\n",
    "model_2_3 = build_model_2(encoder_2_3)\n",
    "model_2_3.load_weights('../input/ubiquantfulltrainsubweights/m2_3_fulltr-origin-seed72-test-1-ep7-loss0.8176.h5')\n",
    "#1516\n",
    "model_2_4 = build_model_2(encoder_2_4)\n",
    "model_2_4.load_weights('../input/ubiquantfulltrainsubweights/m2_4_fulltr-tfrecords-origin-test-3-ep7-loss0.8170.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea0b452c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:44.500292Z",
     "iopub.status.busy": "2022-04-19T13:58:44.499286Z",
     "iopub.status.idle": "2022-04-19T13:58:44.500928Z",
     "shell.execute_reply": "2022-04-19T13:58:44.501338Z",
     "shell.execute_reply.started": "2022-04-18T16:47:58.37404Z"
    },
    "papermill": {
     "duration": 0.120917,
     "end_time": "2022-04-19T13:58:44.501471",
     "exception": false,
     "start_time": "2022-04-19T13:58:44.380554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_test_dataset(feature, batch_size=2048):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((feature)))\n",
    "    ds = ds.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21df268d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T13:58:44.746638Z",
     "iopub.status.busy": "2022-04-19T13:58:44.743205Z",
     "iopub.status.idle": "2022-04-19T13:59:01.432679Z",
     "shell.execute_reply": "2022-04-19T13:59:01.433110Z",
     "shell.execute_reply.started": "2022-04-18T16:47:58.382081Z"
    },
    "papermill": {
     "duration": 16.818095,
     "end_time": "2022-04-19T13:59:01.433311",
     "exception": false,
     "start_time": "2022-04-19T13:58:44.615216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    try:\n",
    "        data_ox = test_df.drop(columns=['row_id', 'investment_id']).values\n",
    "        \n",
    "        new_model_data = scaler_0.transform(data_ox)\n",
    "        new_model_data = make_test_dataset(new_model_data)\n",
    "        \n",
    "        data_ox = scaler.transform(data_ox)\n",
    "        data_ox = make_test_dataset(data_ox)\n",
    "\n",
    "        t0 = (model_0.predict(data_ox) * 1.521 +\n",
    "              model_0_0.predict(data_ox) * 1.515 +\n",
    "             model_0_2.predict(data_ox) * 1.532 +\n",
    "             model_1.predict(data_ox) * 1.521 +\n",
    "             model_1_0.predict(data_ox) * 1.520 +\n",
    "             model_2.predict(data_ox) * 1.523 +\n",
    "             model_2_0.predict(data_ox) * 1.501 +\n",
    "             model_2_1.predict(data_ox) * 1.514 +\n",
    "             model_2_2.predict(data_ox) * 1.511 +\n",
    "             model_2_4.predict(data_ox) * 1.516) \n",
    "        t0[np.isnan(t0)] = 0\n",
    "        t0 = t0 / 15.0\n",
    "        \n",
    "        \n",
    "        t1 = model_bigdrop_bt512[0].predict(data_ox)\n",
    "        for i in range(1, len(model_bigdrop_bt512)):\n",
    "            t1 = t1 + model_bigdrop_bt512[i].predict(data_ox)\n",
    "        t1[np.isnan(t1)] = 0\n",
    "        t1 = t1 / len(model_bigdrop_bt512)\n",
    "\n",
    "        \n",
    "        t2 = model_bigdrop_bt1024[0].predict(data_ox)\n",
    "        for i in range(1, len(model_bigdrop_bt1024)):\n",
    "            t2 = t2 + model_bigdrop_bt1024[i].predict(data_ox)\n",
    "        t2[np.isnan(t2)] = 0\n",
    "        t2 = t2 / len(model_bigdrop_bt1024)\n",
    "\n",
    "        \n",
    "        t3 = model_bigdrop_1_bt1024[0].predict(data_ox)\n",
    "        for i in range(1, len(model_bigdrop_1_bt1024)):\n",
    "            t3 = t3 + model_bigdrop_1_bt1024[i].predict(data_ox)\n",
    "        t3[np.isnan(t3)] = 0\n",
    "        t3 = t3 / len(model_bigdrop_1_bt1024)\n",
    "        \n",
    "        \n",
    "        t4 = model_bigdrop_fold6[0].predict(data_ox)\n",
    "        for i in range(1, len(model_bigdrop_fold6)):\n",
    "            t4 = t4 + model_bigdrop_fold6[i].predict(data_ox)\n",
    "        t4[np.isnan(t4)] = 0\n",
    "        t4 = t4 / len(model_bigdrop_fold6)\n",
    "        \n",
    "        \n",
    "        t5 = model_bigdrop_fold14[0].predict(data_ox)\n",
    "        for i in range(1, len(model_bigdrop_fold14)):\n",
    "            t5 = t5 + model_bigdrop_fold14[i].predict(data_ox)\n",
    "        t5[np.isnan(t5)] = 0\n",
    "        t5 = t5 / len(model_bigdrop_fold14)\n",
    "        \n",
    "        t6 = new_model[0].predict(new_model_data) + new_model[1].predict(new_model_data) + new_model[2].predict(new_model_data)\n",
    "        t6[np.isnan(t6)] = 0\n",
    "        t6 = t6 / 3.0\n",
    "        \n",
    "        sample_prediction_df['target'] = (t0 + t1 + t2 + t3) / 4.0 * 0.3 + t4 * 0.065 + t5 * 0.115 + t6 * 0.52\n",
    "\n",
    "    except Exception:\n",
    "        sample_prediction_df['target'] = np.random.randn(len(sample_prediction_df))\n",
    "    \n",
    "    env.predict(sample_prediction_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7122.287237,
   "end_time": "2022-04-19T13:59:04.736889",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-19T12:00:22.449652",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
